<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>BORG Enforcement Surface Specification • BORG</title><script src="lightswitch.js"></script><script src="deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link href="deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet"><script src="deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet"><link href="deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet"><script src="deps/headroom-0.11.0/headroom.min.js"></script><script src="deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="deps/search-1.0.0/fuse.min.js"></script><script src="deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="pkgdown.js"></script><link href="extra.css" rel="stylesheet"><meta property="og:title" content="BORG Enforcement Surface Specification"><script>
// Redirect any case variation of /borg to /BORG
(function() {
  var path = window.location.pathname;
  if (/^\/borg\b/i.test(path) && !/^\/BORG/.test(path)) {
    var newPath = path.replace(/^\/borg/i, '/BORG');
    window.location.replace(newPath + window.location.search + window.location.hash);
  }
})();
</script></head><body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top " aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="index.html">BORG</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.1.1</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto"><li class="nav-item"><a class="nav-link" href="articles/quickstart.html">Get Started</a></li>
<li class="nav-item"><a class="nav-link" href="reference/index.html">Reference</a></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles"><li><a class="dropdown-item" href="articles/quickstart.html">Quick Start</a></li>
    <li><a class="dropdown-item" href="articles/risk-taxonomy.html">Risk Taxonomy</a></li>
    <li><a class="dropdown-item" href="articles/frameworks.html">Framework Integration</a></li>
  </ul></li>
<li class="nav-item"><a class="nav-link" href="news/index.html">Changelog</a></li>
      </ul><ul class="navbar-nav"><li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="search.json"></form></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-lightswitch" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true" aria-label="Light switch"><span class="fa fa-sun"></span></button>
  <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="dropdown-lightswitch"><li><button class="dropdown-item" data-bs-theme-value="light"><span class="fa fa-sun"></span> Light</button></li>
    <li><button class="dropdown-item" data-bs-theme-value="dark"><span class="fa fa-moon"></span> Dark</button></li>
    <li><button class="dropdown-item" data-bs-theme-value="auto"><span class="fa fa-adjust"></span> Auto</button></li>
  </ul></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/gcol33/BORG" aria-label="GitHub"><span class="fa fab fa-github"></span></a></li>
      </ul></div>


  </div>
</nav><div class="container template-title-body">
<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>BORG Enforcement Surface Specification</h1>
      <small class="dont-index">Source: <a href="https://github.com/gcol33/BORG/blob/HEAD/ENFORCEMENT_SURFACE.md" class="external-link"><code>ENFORCEMENT_SURFACE.md</code></a></small>
    </div>

<div id="borg-enforcement-surface-specification" class="section level1">

<p><strong>Version:</strong> 1.0.0 <strong>Status:</strong> Frozen <strong>Last Modified:</strong> 2025-01-07</p>
<blockquote>
<p>This document is the authoritative contract for BORG’s enforcement behavior. Changes require a rationale entry in the changelog below.</p>
</blockquote>
<hr><div class="section level2">
<h2 id="changelog">Changelog<a class="anchor" aria-label="anchor" href="#changelog"></a></h2>
<table class="table"><colgroup><col width="26%"><col width="17%"><col width="23%"><col width="32%"></colgroup><thead><tr><th>Version</th>
<th>Date</th>
<th>Change</th>
<th>Rationale</th>
</tr></thead><tbody><tr><td>1.0.0</td>
<td>2025-01-07</td>
<td>Initial specification</td>
<td>Defines complete enforcement surface for v0.1.0 release</td>
</tr></tbody></table><hr></div>
<div class="section level2">
<h2 id="governing-principles">Governing Principles<a class="anchor" aria-label="anchor" href="#governing-principles"></a></h2>
<ol style="list-style-type: decimal"><li>
<strong>BORG is a gate, not a linter.</strong> Invalid evaluations do not proceed.</li>
<li>
<strong>Fail closed.</strong> Ambiguous cases block rather than warn.</li>
<li>
<strong>No metrics leave the system unless valid.</strong> Performance estimates from compromised evaluations are not computed.</li>
<li>
<strong>Actions are verbs.</strong> Block, Rewrite, Constrain. Not “Warn” or “Inform”.</li>
<li>
<strong>Risk is defined at the outcome layer.</strong> Validity of conclusions, not correctness of technique.</li>
</ol><hr></div>
<div class="section level2">
<h2 id="risk-classification-definitions">Risk Classification Definitions<a class="anchor" aria-label="anchor" href="#risk-classification-definitions"></a></h2>
<p><strong>Hard Violation</strong>: The evaluation is fundamentally invalid. Results cannot be trusted under any interpretation. BORG must refuse to compute or must block the operation.</p>
<p><strong>Soft Inflation</strong>: Results are biased but bounded. Performance estimates are misleading but may retain ordinal validity (model ranking may be preserved). BORG may allow with enforced constraints or automatic rewriting.</p>
<hr></div>
<div class="section level2">
<h2 id="id_1-cross-validation-schemes">1. Cross-Validation Schemes<a class="anchor" aria-label="anchor" href="#id_1-cross-validation-schemes"></a></h2>
<div class="section level3">
<h3 id="id_11-k-fold-cross-validation">1.1 K-Fold Cross-Validation<a class="anchor" aria-label="anchor" href="#id_11-k-fold-cross-validation"></a></h3>
<p><strong>Observable Signals in R:</strong> - <code>caret::trainControl</code> objects with <code>index</code>/<code>indexOut</code> slots - <code>rsample::vfold_cv</code> objects storing fold assignments - Custom fold vectors as integer indices - Preprocessing objects (<code>recipes::recipe</code>, <code>caret::preProcess</code>) fitted before splitting</p>
<p><strong>Detection Method:</strong> - Check if preprocessing parameters (mean, sd, PCA loadings) were computed on full data - Inspect <code>recipe$template</code> row count vs training fold sizes - Compare <code>preProcess$mean</code> against fold-specific means</p>
<p><strong>Risk Classification:</strong> Hard Violation (if preprocessing leaks), Soft Inflation (if only minor statistics leak)</p>
<p><strong>Enforcement Action:</strong> - <strong>Block</strong>: If <code>preProcess</code> or <code>recipe</code> fitted on full data before fold creation - <strong>Rewrite</strong>: Inject preprocessing into each fold’s training pipeline automatically</p>
<hr></div>
<div class="section level3">
<h3 id="id_12-stratified-k-fold">1.2 Stratified K-Fold<a class="anchor" aria-label="anchor" href="#id_12-stratified-k-fold"></a></h3>
<p><strong>Observable Signals in R:</strong> - <code>caret::createFolds(y, k, list = TRUE)</code> with class imbalance - <code>rsample::vfold_cv(strata = ...)</code> specification - Class distribution in each fold vs natural distribution</p>
<p><strong>Detection Method:</strong> - Compare class proportions per fold to full dataset - Check if rare classes are artificially balanced across folds - Detect if stratification variable has temporal/spatial structure</p>
<p><strong>Risk Classification:</strong> Soft Inflation</p>
<p><strong>Enforcement Action:</strong> - <strong>Allow with constraints</strong>: Warn if class proportions are artificially balanced - Flag if stratification variable correlates with time/space indices</p>
<hr></div>
<div class="section level3">
<h3 id="id_13-leave-one-out-cross-validation-loocv">1.3 Leave-One-Out Cross-Validation (LOOCV)<a class="anchor" aria-label="anchor" href="#id_13-leave-one-out-cross-validation-loocv"></a></h3>
<p><strong>Observable Signals in R:</strong> - <code>caret::trainControl(method = "LOOCV")</code> - <code>rsample::loo_cv()</code> objects - Fold count equals row count</p>
<p><strong>Detection Method:</strong> - Check <code>length(folds) == nrow(data)</code> - Detect global preprocessing before LOOCV</p>
<p><strong>Risk Classification:</strong> Hard Violation (preprocessing leak is amplified), Soft Inflation (variance estimates unreliable)</p>
<p><strong>Enforcement Action:</strong> - <strong>Block</strong>: If any global preprocessing detected - <strong>Allow with constraints</strong>: Require acknowledgment that variance estimates are correlated</p>
<hr></div>
<div class="section level3">
<h3 id="id_14-repeated-cross-validation">1.4 Repeated Cross-Validation<a class="anchor" aria-label="anchor" href="#id_14-repeated-cross-validation"></a></h3>
<p><strong>Observable Signals in R:</strong> - <code>caret::trainControl(method = "repeatedcv", repeats = n)</code> - Multiple <code>rsample::vfold_cv</code> objects with different seeds - Aggregated metrics across repetitions</p>
<p><strong>Detection Method:</strong> - Check for consistent bias direction across repetitions - Detect if preprocessing was fitted once and reused across all repetitions</p>
<p><strong>Risk Classification:</strong> Soft Inflation (averaging hides but doesn’t fix bias)</p>
<p><strong>Enforcement Action:</strong> - <strong>Allow with constraints</strong>: Verify each repetition independently enforces anti-leakage - Warn that stability ≠ validity</p>
<hr></div>
<div class="section level3">
<h3 id="id_15-nested-cross-validation">1.5 Nested Cross-Validation<a class="anchor" aria-label="anchor" href="#id_15-nested-cross-validation"></a></h3>
<p><strong>Observable Signals in R:</strong> - <code>caret::trainControl</code> with <code>search = "grid"</code> or <code>"random"</code> inside outer loop - <code>mlr3::ResamplingNested</code> objects - Inner/outer fold structure in tuning results</p>
<p><strong>Detection Method:</strong> - Trace data flow: outer test indices must not appear in inner loop computations - Check early stopping criteria against outer fold data - Inspect threshold selection data source</p>
<p><strong>Risk Classification:</strong> Hard Violation (if outer fold influences inner loop)</p>
<p><strong>Enforcement Action:</strong> - <strong>Block</strong>: If outer test data indices appear in inner tuning decisions - <strong>Rewrite</strong>: Enforce strict index separation between inner and outer loops</p>
<hr></div>
<div class="section level3">
<h3 id="id_16-group-k-fold--leave-one-group-out">1.6 Group K-Fold / Leave-One-Group-Out<a class="anchor" aria-label="anchor" href="#id_16-group-k-fold--leave-one-group-out"></a></h3>
<p><strong>Observable Signals in R:</strong> - <code>caret::groupKFold(group, k)</code> with group vector - <code>rsample::group_vfold_cv(group = ...)</code> specification - Group column in data frame</p>
<p><strong>Detection Method:</strong> - Check for unique groups in train vs test (no overlap) - Detect if group variable fully captures dependency structure - Test for residual within-group correlation in features</p>
<p><strong>Risk Classification:</strong> Hard Violation (if groups overlap), Soft Inflation (if grouping insufficient)</p>
<p><strong>Enforcement Action:</strong> - <strong>Block</strong>: If any group ID appears in both train and test - <strong>Allow with constraints</strong>: Require grouping variable to be validated against correlation structure</p>
<hr></div>
</div>
<div class="section level2">
<h2 id="id_2-train-test-splits">2. Train-Test Splits<a class="anchor" aria-label="anchor" href="#id_2-train-test-splits"></a></h2>
<div class="section level3">
<h3 id="id_21-random-hold-out-split">2.1 Random Hold-Out Split<a class="anchor" aria-label="anchor" href="#id_21-random-hold-out-split"></a></h3>
<p><strong>Observable Signals in R:</strong> - <code>caret::createDataPartition()</code> output - <code>rsample::initial_split()</code> objects - Row indices in train/test - <code>.Random.seed</code> state at split time</p>
<p><strong>Detection Method:</strong> - Check if split was created before or after exploratory analysis - Detect if test indices were accessed before final evaluation - Track call history for test set access patterns</p>
<p><strong>Risk Classification:</strong> Soft Inflation (if split timing uncertain)</p>
<p><strong>Enforcement Action:</strong> - <strong>Allow with constraints</strong>: Require split creation timestamp before any data exploration - Log all test set accesses</p>
<hr></div>
<div class="section level3">
<h3 id="id_22-multiple-random-splits-with-selection">2.2 Multiple Random Splits with Selection<a class="anchor" aria-label="anchor" href="#id_22-multiple-random-splits-with-selection"></a></h3>
<p><strong>Observable Signals in R:</strong> - Multiple split objects with different seeds - Results object containing metrics from multiple splits - Reported metric differs from full distribution of split metrics</p>
<p><strong>Detection Method:</strong> - Compare reported metric to mean/median across all splits - Detect if only best/worst splits are reported - Check for selective reporting patterns</p>
<p><strong>Risk Classification:</strong> Soft Inflation (selective reporting inflates estimates)</p>
<p><strong>Enforcement Action:</strong> - <strong>Allow with constraints</strong>: Require reporting of all splits or pre-registered single split - Block selective metric reporting</p>
<hr></div>
<div class="section level3">
<h3 id="id_23-data-snooping-through-iterative-refinement">2.3 Data Snooping Through Iterative Refinement<a class="anchor" aria-label="anchor" href="#id_23-data-snooping-through-iterative-refinement"></a></h3>
<p><strong>Observable Signals in R:</strong> - <code><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict()</a></code> call count on test set - Model version history with test evaluations interleaved - Incrementing model modifications after each test evaluation</p>
<p><strong>Detection Method:</strong> - Count test set evaluation events - Track model object modifications between test evaluations - Detect if hyperparameters change after test feedback</p>
<p><strong>Risk Classification:</strong> Hard Violation (test set becomes validation set)</p>
<p><strong>Enforcement Action:</strong> - <strong>Block</strong>: After first test evaluation, refuse further evaluations on same data - Enforce single-use test set policy</p>
<hr></div>
</div>
<div class="section level2">
<h2 id="id_3-temporal-evaluation-schemes">3. Temporal Evaluation Schemes<a class="anchor" aria-label="anchor" href="#id_3-temporal-evaluation-schemes"></a></h2>
<div class="section level3">
<h3 id="id_31-walk-forward--expanding-window-backtest">3.1 Walk-Forward / Expanding Window Backtest<a class="anchor" aria-label="anchor" href="#id_31-walk-forward--expanding-window-backtest"></a></h3>
<p><strong>Observable Signals in R:</strong> - <code>rsample::sliding_window()</code> / <code>rolling_origin()</code> objects - Time index column in data - Feature columns with future-derived values</p>
<p><strong>Detection Method:</strong> - Check feature timestamps against prediction timestamps - Detect if features contain information from t+k for predictions at t - Validate that model at time t uses only data ≤ t</p>
<p><strong>Risk Classification:</strong> Hard Violation (look-ahead bias)</p>
<p><strong>Enforcement Action:</strong> - <strong>Block</strong>: If any feature timestamp exceeds prediction timestamp - <strong>Rewrite</strong>: Automatically filter features to respect temporal ordering</p>
<hr></div>
<div class="section level3">
<h3 id="id_32-rolling-window-backtest">3.2 Rolling Window Backtest<a class="anchor" aria-label="anchor" href="#id_32-rolling-window-backtest"></a></h3>
<p><strong>Observable Signals in R:</strong> - Fixed window size parameter - Window size selection methodology - Regime change indicators in time series</p>
<p><strong>Detection Method:</strong> - Check if window size was optimized using future data - Detect regime changes that window spans inappropriately - Verify stationarity assumption within windows</p>
<p><strong>Risk Classification:</strong> Soft Inflation (if window size data-snooped)</p>
<p><strong>Enforcement Action:</strong> - <strong>Allow with constraints</strong>: Require window size to be pre-specified or selected on past data only</p>
<hr></div>
<div class="section level3">
<h3 id="id_33-purged-and-embargoed-cross-validation">3.3 Purged and Embargoed Cross-Validation<a class="anchor" aria-label="anchor" href="#id_33-purged-and-embargoed-cross-validation"></a></h3>
<p><strong>Observable Signals in R:</strong> - Purge gap parameter (rows removed near boundary) - Embargo period parameter - Autocorrelation structure of target/features</p>
<p><strong>Detection Method:</strong> - Compare embargo period to measured autocorrelation decay - Check if purge removes all serially dependent observations - Validate embargo against feature autocorrelation, not just target</p>
<p><strong>Risk Classification:</strong> Soft Inflation (if embargo insufficient)</p>
<p><strong>Enforcement Action:</strong> - <strong>Allow with constraints</strong>: Require embargo ≥ autocorrelation decay length - Warn if measured autocorrelation exceeds embargo</p>
<hr></div>
<div class="section level3">
<h3 id="id_34-point-in-time-feature-construction">3.4 Point-in-Time Feature Construction<a class="anchor" aria-label="anchor" href="#id_34-point-in-time-feature-construction"></a></h3>
<p><strong>Observable Signals in R:</strong> - Data vintage timestamps (if available) - Revised vs preliminary data indicators - Feature values that changed after creation date</p>
<p><strong>Detection Method:</strong> - Check for data revision columns - Compare feature values to vintage-specific values - Detect anachronistic feature values</p>
<p><strong>Risk Classification:</strong> Hard Violation (look-ahead through revisions)</p>
<p><strong>Enforcement Action:</strong> - <strong>Block</strong>: If revised data used without vintage timestamps - Require point-in-time database or vintage column</p>
<hr></div>
</div>
<div class="section level2">
<h2 id="id_4-spatial-and-hierarchical-evaluation">4. Spatial and Hierarchical Evaluation<a class="anchor" aria-label="anchor" href="#id_4-spatial-and-hierarchical-evaluation"></a></h2>
<div class="section level3">
<h3 id="id_41-spatial-cross-validation-block-cv">4.1 Spatial Cross-Validation (Block CV)<a class="anchor" aria-label="anchor" href="#id_41-spatial-cross-validation-block-cv"></a></h3>
<p><strong>Observable Signals in R:</strong> - <code>sf</code> spatial objects with coordinates - <code>sp::SpatialPoints</code> coordinate data - <code>blockCV</code> or <code>spatialsample</code> fold objects - Spatial block size parameter</p>
<p><strong>Detection Method:</strong> - Compute spatial autocorrelation range (variogram) - Compare block size to autocorrelation range - Detect if train/test blocks are spatially adjacent</p>
<p><strong>Risk Classification:</strong> Soft Inflation (if blocks too small)</p>
<p><strong>Enforcement Action:</strong> - <strong>Allow with constraints</strong>: Require block size ≥ autocorrelation range - Warn if spatial leakage detected between adjacent blocks</p>
<hr></div>
<div class="section level3">
<h3 id="id_42-leave-one-location-out-spatial-transfer">4.2 Leave-One-Location-Out (Spatial Transfer)<a class="anchor" aria-label="anchor" href="#id_42-leave-one-location-out-spatial-transfer"></a></h3>
<p><strong>Observable Signals in R:</strong> - Location/site column in data - Coordinates per location - Environmental covariates per location</p>
<p><strong>Detection Method:</strong> - Check spatial separation between train and test locations - Detect if test locations are within convex hull of training locations - Compare environmental envelopes of train vs test</p>
<p><strong>Risk Classification:</strong> Soft Inflation (interpolation vs extrapolation confusion)</p>
<p><strong>Enforcement Action:</strong> - <strong>Allow with constraints</strong>: Flag if test locations are interpolative, not extrapolative - Require explicit statement of transfer claim scope</p>
<hr></div>
<div class="section level3">
<h3 id="id_43-clustered-standard-errors-without-clustered-cv">4.3 Clustered Standard Errors Without Clustered CV<a class="anchor" aria-label="anchor" href="#id_43-clustered-standard-errors-without-clustered-cv"></a></h3>
<p><strong>Observable Signals in R:</strong> - <code>sandwich::vcovCL()</code> or <code>clubSandwich</code> usage post-hoc - Cluster variable present but not used in CV splitting - <code>lme4::lmer()</code> random effects without grouped CV</p>
<p><strong>Detection Method:</strong> - Check if cluster variable exists but CV ignored it - Detect cluster-aware standard errors applied to non-clustered CV results</p>
<p><strong>Risk Classification:</strong> Soft Inflation (point estimates biased, SE correction insufficient)</p>
<p><strong>Enforcement Action:</strong> - <strong>Block</strong>: Standard errors from non-clustered CV with clustered correction - <strong>Rewrite</strong>: Force cluster-aware CV splitting</p>
<hr></div>
</div>
<div class="section level2">
<h2 id="id_5-simulation-based-evaluation">5. Simulation-Based Evaluation<a class="anchor" aria-label="anchor" href="#id_5-simulation-based-evaluation"></a></h2>
<div class="section level3">
<h3 id="id_51-in-silico-validation-with-known-ground-truth">5.1 In-Silico Validation with Known Ground Truth<a class="anchor" aria-label="anchor" href="#id_51-in-silico-validation-with-known-ground-truth"></a></h3>
<p><strong>Observable Signals in R:</strong> - Simulation function parameters - Model architecture designed with knowledge of simulation - Simulation-to-model alignment</p>
<p><strong>Detection Method:</strong> - Check if simulation parameters were fixed before model development - Detect if model architecture exploits known simulation structure - Compare model assumptions to simulation assumptions</p>
<p><strong>Risk Classification:</strong> Soft Inflation (alignment may not generalize)</p>
<p><strong>Enforcement Action:</strong> - <strong>Allow with constraints</strong>: Require simulation parameters to be pre-specified - Warn if model assumptions match simulation assumptions exactly</p>
<hr></div>
<div class="section level3">
<h3 id="id_52-synthetic-data-augmentation-evaluated-on-real-test-set">5.2 Synthetic Data Augmentation Evaluated on Real Test Set<a class="anchor" aria-label="anchor" href="#id_52-synthetic-data-augmentation-evaluated-on-real-test-set"></a></h3>
<p><strong>Observable Signals in R:</strong> - Synthetic data generator (GAN, SMOTE, etc.) - Generator training data includes test set - Augmented training data contains synthetic samples</p>
<p><strong>Detection Method:</strong> - Trace generator training data indices - Check if generator saw test set before augmentation - Validate generator training used only train split</p>
<p><strong>Risk Classification:</strong> Hard Violation (test set information in augmented training)</p>
<p><strong>Enforcement Action:</strong> - <strong>Block</strong>: If generator trained on data including test indices - <strong>Rewrite</strong>: Retrain generator on train-only data</p>
<hr></div>
<div class="section level3">
<h3 id="id_53-bootstrap-performance-estimates">5.3 Bootstrap Performance Estimates<a class="anchor" aria-label="anchor" href="#id_53-bootstrap-performance-estimates"></a></h3>
<p><strong>Observable Signals in R:</strong> - <code><a href="https://rdrr.io/pkg/boot/man/boot.html" class="external-link">boot::boot()</a></code> results - <code>.632</code> or <code>.632+</code> estimator specification - Bootstrap sample indices</p>
<p><strong>Detection Method:</strong> - Check bootstrap estimator assumptions against data dimensionality - Detect high-dimensional settings where .632 correction fails - Validate that out-of-bag samples are genuinely independent</p>
<p><strong>Risk Classification:</strong> Soft Inflation (bias correction may be incorrect)</p>
<p><strong>Enforcement Action:</strong> - <strong>Allow with constraints</strong>: Warn in high-dimensional settings - Require explicit acknowledgment of estimator assumptions</p>
<hr></div>
</div>
<div class="section level2">
<h2 id="id_6-target-and-feature-leakage-patterns">6. Target and Feature Leakage Patterns<a class="anchor" aria-label="anchor" href="#id_6-target-and-feature-leakage-patterns"></a></h2>
<div class="section level3">
<h3 id="id_61-target-leakage-direct">6.1 Target Leakage (Direct)<a class="anchor" aria-label="anchor" href="#id_61-target-leakage-direct"></a></h3>
<p><strong>Observable Signals in R:</strong> - Feature names suggesting outcome derivation (“diagnosis_date”, “outcome_indicator”) - Perfect or near-perfect correlation between feature and target - Feature creation timestamp after target determination</p>
<p><strong>Detection Method:</strong> - Scan feature names for target-derived patterns - Check feature-target correlations &gt; 0.95 - Validate causal ordering if metadata available</p>
<p><strong>Risk Classification:</strong> Hard Violation (trivial prediction, no generalization)</p>
<p><strong>Enforcement Action:</strong> - <strong>Block</strong>: If feature correlates &gt; 0.99 with target - Flag features with suspicious names for manual review</p>
<hr></div>
<div class="section level3">
<h3 id="id_62-target-leakage-indirectproxy">6.2 Target Leakage (Indirect/Proxy)<a class="anchor" aria-label="anchor" href="#id_62-target-leakage-indirectproxy"></a></h3>
<p><strong>Observable Signals in R:</strong> - Features correlated with target only through confounders - Feature importance concentrated on likely proxy variables - Domain-inconsistent feature-target relationships</p>
<p><strong>Detection Method:</strong> - Check if high-importance features have plausible causal paths - Detect features that are proxies for group membership - Flag features with implausibly strong predictive power</p>
<p><strong>Risk Classification:</strong> Soft Inflation (may not generalize under distribution shift)</p>
<p><strong>Enforcement Action:</strong> - <strong>Allow with constraints</strong>: Require domain validation of feature-target relationships - Warn on suspiciously powerful features</p>
<hr></div>
<div class="section level3">
<h3 id="id_63-train-test-leakage-through-identifiers">6.3 Train-Test Leakage Through Identifiers<a class="anchor" aria-label="anchor" href="#id_63-train-test-leakage-through-identifiers"></a></h3>
<p><strong>Observable Signals in R:</strong> - ID columns in data (row names, explicit ID column) - Duplicate rows between train and test - Near-duplicate detection (high similarity between train/test rows)</p>
<p><strong>Detection Method:</strong> - Check for duplicate row hashes between train/test - Detect shared ID values across splits - Compute nearest-neighbor distances between train and test</p>
<p><strong>Risk Classification:</strong> Hard Violation (memorization, not learning)</p>
<p><strong>Enforcement Action:</strong> - <strong>Block</strong>: If any ID appears in both train and test - <strong>Block</strong>: If duplicate rows exist across splits - Warn on near-duplicates (cosine similarity &gt; 0.99)</p>
<hr></div>
<div class="section level3">
<h3 id="id_64-leakage-through-global-feature-engineering">6.4 Leakage Through Global Feature Engineering<a class="anchor" aria-label="anchor" href="#id_64-leakage-through-global-feature-engineering"></a></h3>
<p><strong>Observable Signals in R:</strong> - Target encoding computed on full data - Frequency statistics from full data - Embeddings (word2vec, PCA) fitted on full data</p>
<p><strong>Detection Method:</strong> - Trace feature engineering objects to their training data - Check if encoding/embedding objects used train+test - Validate feature statistics against train-only statistics</p>
<p><strong>Risk Classification:</strong> Hard Violation (test statistics in training features)</p>
<p><strong>Enforcement Action:</strong> - <strong>Block</strong>: If feature engineering objects fitted on full data - <strong>Rewrite</strong>: Recompute features within each fold using train-only data</p>
<hr></div>
</div>
<div class="section level2">
<h2 id="id_7-metric-and-threshold-selection">7. Metric and Threshold Selection<a class="anchor" aria-label="anchor" href="#id_7-metric-and-threshold-selection"></a></h2>
<div class="section level3">
<h3 id="id_71-threshold-optimization-on-test-data">7.1 Threshold Optimization on Test Data<a class="anchor" aria-label="anchor" href="#id_71-threshold-optimization-on-test-data"></a></h3>
<p><strong>Observable Signals in R:</strong> - <code>pROC::coords()</code> optimal threshold from test ROC - Threshold selection code accessing test labels - Multiple thresholds evaluated on test set</p>
<p><strong>Detection Method:</strong> - Check if threshold selection used test labels - Trace threshold value origin to train vs test data - Detect threshold optimization loops over test data</p>
<p><strong>Risk Classification:</strong> Hard Violation (threshold is a model parameter)</p>
<p><strong>Enforcement Action:</strong> - <strong>Block</strong>: If threshold selected using test labels - <strong>Rewrite</strong>: Move threshold selection to validation set</p>
<hr></div>
<div class="section level3">
<h3 id="id_72-metric-selection-after-results-are-known">7.2 Metric Selection After Results Are Known<a class="anchor" aria-label="anchor" href="#id_72-metric-selection-after-results-are-known"></a></h3>
<p><strong>Observable Signals in R:</strong> - Multiple metrics computed, subset reported - Metric choice differs from pre-registration (if any) - Primary metric declaration after evaluation</p>
<p><strong>Detection Method:</strong> - Check if primary metric was declared before evaluation - Detect selective metric reporting - Compare reported metrics to computed metrics</p>
<p><strong>Risk Classification:</strong> Soft Inflation (favorable metric selection)</p>
<p><strong>Enforcement Action:</strong> - <strong>Allow with constraints</strong>: Require pre-specified primary metric - Report all computed metrics if primary not pre-specified</p>
<hr></div>
<div class="section level3">
<h3 id="id_73-subgroup-analysis-post-hoc">7.3 Subgroup Analysis Post Hoc<a class="anchor" aria-label="anchor" href="#id_73-subgroup-analysis-post-hoc"></a></h3>
<p><strong>Observable Signals in R:</strong> - Subgroup definitions created after test evaluation - Subgroup-specific metrics showing heterogeneous performance - Subgroups discovered through test set analysis</p>
<p><strong>Detection Method:</strong> - Check if subgroup definitions predate test evaluation - Detect subgroups with anomalously good/bad performance - Trace subgroup discovery to train vs test data</p>
<p><strong>Risk Classification:</strong> Soft Inflation (cherry-picking favorable subgroups)</p>
<p><strong>Enforcement Action:</strong> - <strong>Allow with constraints</strong>: Require subgroup pre-specification or discovery on train data only - Flag post-hoc subgroup analyses</p>
<hr></div>
</div>
<div class="section level2">
<h2 id="id_8-external-validation-and-transfer-evaluation">8. External Validation and Transfer Evaluation<a class="anchor" aria-label="anchor" href="#id_8-external-validation-and-transfer-evaluation"></a></h2>
<div class="section level3">
<h3 id="id_81-external-validation-on-overlapping-populations">8.1 External Validation on Overlapping Populations<a class="anchor" aria-label="anchor" href="#id_81-external-validation-on-overlapping-populations"></a></h3>
<p><strong>Observable Signals in R:</strong> - Shared time period, geography, or institution between datasets - Similar covariate distributions between train and external - Overlapping collection protocols</p>
<p><strong>Detection Method:</strong> - Compare covariate distributions (train vs external) - Check metadata for overlap in time/space/institution - Compute domain shift metrics (MMD, KL divergence)</p>
<p><strong>Risk Classification:</strong> Soft Inflation (narrow generalization scope)</p>
<p><strong>Enforcement Action:</strong> - <strong>Allow with constraints</strong>: Require documentation of overlap dimensions - Warn if external data too similar to training data</p>
<hr></div>
<div class="section level3">
<h3 id="id_82-transfer-learning-evaluation-with-shared-pretraining-data">8.2 Transfer Learning Evaluation with Shared Pretraining Data<a class="anchor" aria-label="anchor" href="#id_82-transfer-learning-evaluation-with-shared-pretraining-data"></a></h3>
<p><strong>Observable Signals in R:</strong> - Foundation model with unknown pretraining data - Test data potentially in pretraining corpus - Zero-shot or few-shot evaluation on common benchmarks</p>
<p><strong>Detection Method:</strong> - Check for known contamination (benchmark data in pretraining) - Detect memorization signals (verbatim reproduction) - Validate test data was verifiably excluded from pretraining</p>
<p><strong>Risk Classification:</strong> Hard Violation (memorization, not transfer)</p>
<p><strong>Enforcement Action:</strong> - <strong>Block</strong>: If test data known to be in pretraining - Require contamination audit or held-out test sets</p>
<hr></div>
<div class="section level3">
<h3 id="id_83-domain-adaptation-with-target-domain-labels">8.3 Domain Adaptation with Target Domain Labels<a class="anchor" aria-label="anchor" href="#id_83-domain-adaptation-with-target-domain-labels"></a></h3>
<p><strong>Observable Signals in R:</strong> - Labeled target domain data used for adaptation - Same target data used for adaptation and evaluation - No held-out target domain test set</p>
<p><strong>Detection Method:</strong> - Check if adaptation data overlaps with evaluation data - Trace label usage in adaptation procedure - Validate separate adaptation vs evaluation splits</p>
<p><strong>Risk Classification:</strong> Hard Violation (circular evaluation)</p>
<p><strong>Enforcement Action:</strong> - <strong>Block</strong>: If adaptation and evaluation use same labeled data - <strong>Rewrite</strong>: Split target domain into adaptation and evaluation sets</p>
<hr></div>
</div>
<div class="section level2">
<h2 id="id_9-ensemble-and-model-selection-leakage">9. Ensemble and Model Selection Leakage<a class="anchor" aria-label="anchor" href="#id_9-ensemble-and-model-selection-leakage"></a></h2>
<div class="section level3">
<h3 id="id_91-stackingblending-with-validation-set-reuse">9.1 Stacking/Blending with Validation Set Reuse<a class="anchor" aria-label="anchor" href="#id_91-stackingblending-with-validation-set-reuse"></a></h3>
<p><strong>Observable Signals in R:</strong> - Stacking predictions from base models - Meta-learner trained on validation predictions - Same validation set used for base model selection and meta-learner training</p>
<p><strong>Detection Method:</strong> - Trace validation data through base model selection and meta-learner - Check if base model hyperparameters were selected using same data as meta-learner - Detect double-dipping on validation predictions</p>
<p><strong>Risk Classification:</strong> Hard Violation (validation set used twice)</p>
<p><strong>Enforcement Action:</strong> - <strong>Block</strong>: If validation set used for both base selection and meta-training - <strong>Rewrite</strong>: Create four-way split: base train, base validation, meta train, final test</p>
<hr></div>
<div class="section level3">
<h3 id="id_92-hyperparameter-optimization-across-full-dataset">9.2 Hyperparameter Optimization Across Full Dataset<a class="anchor" aria-label="anchor" href="#id_92-hyperparameter-optimization-across-full-dataset"></a></h3>
<p><strong>Observable Signals in R:</strong> - <code>caret::train()</code> with CV including test data - Grid search results using full dataset - Bayesian optimization with test data in CV</p>
<p><strong>Detection Method:</strong> - Check if HPO CV indices overlap with final test indices - Trace hyperparameter selection to data used - Validate HPO was nested within train split</p>
<p><strong>Risk Classification:</strong> Hard Violation (test data influenced hyperparameters)</p>
<p><strong>Enforcement Action:</strong> - <strong>Block</strong>: If HPO used test data in any form - <strong>Rewrite</strong>: Enforce nested CV with strict test set isolation</p>
<hr></div>
<div class="section level3">
<h3 id="id_93-early-stopping-on-test-performance">9.3 Early Stopping on Test Performance<a class="anchor" aria-label="anchor" href="#id_93-early-stopping-on-test-performance"></a></h3>
<p><strong>Observable Signals in R:</strong> - Training history with test metrics at each epoch - <code>keras::EarlyStopping</code> callback on test data - Model selection based on test metric trajectory</p>
<p><strong>Detection Method:</strong> - Check early stopping callback data source - Detect if test metrics influenced training termination - Validate early stopping used validation (not test) data</p>
<p><strong>Risk Classification:</strong> Hard Violation (test set used for model selection)</p>
<p><strong>Enforcement Action:</strong> - <strong>Block</strong>: If early stopping monitored test metrics - <strong>Rewrite</strong>: Redirect early stopping to separate validation set</p>
<hr></div>
</div>
<div class="section level2">
<h2 id="id_10-preprocessing-and-pipeline-leakage">10. Preprocessing and Pipeline Leakage<a class="anchor" aria-label="anchor" href="#id_10-preprocessing-and-pipeline-leakage"></a></h2>
<div class="section level3">
<h3 id="id_101-imputation-fitted-on-full-data">10.1 Imputation Fitted on Full Data<a class="anchor" aria-label="anchor" href="#id_101-imputation-fitted-on-full-data"></a></h3>
<p><strong>Observable Signals in R:</strong> - <code>mice::mice()</code> fitted before splitting - <code>recipes::step_impute_*()</code> trained on full data - <code>caret::preProcess(method = "medianImpute")</code> on full data</p>
<p><strong>Detection Method:</strong> - Check imputation model training data - Compare imputation parameters to train-only statistics - Trace <code>$mean</code>, <code>$median</code> in imputation objects</p>
<p><strong>Risk Classification:</strong> Hard Violation (test statistics in imputed training values)</p>
<p><strong>Enforcement Action:</strong> - <strong>Block</strong>: If imputation fitted on train+test - <strong>Rewrite</strong>: Refit imputation within each fold on train-only data</p>
<hr></div>
<div class="section level3">
<h3 id="id_102-normalizationscaling-with-test-statistics">10.2 Normalization/Scaling with Test Statistics<a class="anchor" aria-label="anchor" href="#id_102-normalizationscaling-with-test-statistics"></a></h3>
<p><strong>Observable Signals in R:</strong> - <code><a href="https://rdrr.io/r/base/scale.html" class="external-link">scale()</a></code> applied to full data before splitting - <code>caret::preProcess(method = c("center", "scale"))</code> on full data - <code>recipes::step_normalize()</code> trained on full data</p>
<p><strong>Detection Method:</strong> - Compare scaling parameters to train-only mean/sd - Check <code>preProcess$mean</code>, <code>preProcess$std</code> against fold statistics - Trace normalization parameters to training data</p>
<p><strong>Risk Classification:</strong> Hard Violation (test scale information in training)</p>
<p><strong>Enforcement Action:</strong> - <strong>Block</strong>: If normalization fitted on train+test - <strong>Rewrite</strong>: Compute normalization on train, apply frozen to test</p>
<hr></div>
<div class="section level3">
<h3 id="id_103-feature-selection-using-test-labels">10.3 Feature Selection Using Test Labels<a class="anchor" aria-label="anchor" href="#id_103-feature-selection-using-test-labels"></a></h3>
<p><strong>Observable Signals in R:</strong> - <code>caret::rfe()</code> using full data - Correlation-based selection on full data - <code>Boruta</code> or similar run before splitting</p>
<p><strong>Detection Method:</strong> - Check if feature selection used test labels - Compare selected features to train-only selection - Trace selection criteria computation to data used</p>
<p><strong>Risk Classification:</strong> Hard Violation (test labels drove feature choice)</p>
<p><strong>Enforcement Action:</strong> - <strong>Block</strong>: If feature selection used test labels - <strong>Rewrite</strong>: Perform feature selection within each fold on train-only</p>
<hr></div>
<div class="section level3">
<h3 id="id_104-dimensionality-reduction-pca-umap-on-full-data">10.4 Dimensionality Reduction (PCA, UMAP) on Full Data<a class="anchor" aria-label="anchor" href="#id_104-dimensionality-reduction-pca-umap-on-full-data"></a></h3>
<p><strong>Observable Signals in R:</strong> - <code><a href="https://rdrr.io/r/stats/prcomp.html" class="external-link">prcomp()</a></code> or <code><a href="https://rdrr.io/r/stats/princomp.html" class="external-link">stats::princomp()</a></code> on full data - <code>umap::umap()</code> fitted before splitting - <code>recipes::step_pca()</code> trained on full data</p>
<p><strong>Detection Method:</strong> - Compare PCA loadings to train-only PCA - Check if UMAP embedding used test data - Trace dimensionality reduction object training data</p>
<p><strong>Risk Classification:</strong> Hard Violation (test structure in reduced space)</p>
<p><strong>Enforcement Action:</strong> - <strong>Block</strong>: If dimensionality reduction fitted on train+test - <strong>Rewrite</strong>: Fit reduction on train, transform test with frozen parameters</p>
<hr></div>
</div>
<div class="section level2">
<h2 id="summary-enforcement-action-matrix">Summary: Enforcement Action Matrix<a class="anchor" aria-label="anchor" href="#summary-enforcement-action-matrix"></a></h2>
<table class="table"><colgroup><col width="32%"><col width="36%"><col width="30%"></colgroup><thead><tr><th>Scheme Category</th>
<th>Primary Detection</th>
<th>Default Action</th>
</tr></thead><tbody><tr><td>Cross-validation preprocessing</td>
<td>
<code>preProcess</code>/<code>recipe</code> timing</td>
<td>Block</td>
</tr><tr><td>Group overlap in CV</td>
<td>Index intersection</td>
<td>Block</td>
</tr><tr><td>Temporal look-ahead</td>
<td>Feature vs target timestamps</td>
<td>Block</td>
</tr><tr><td>Spatial autocorrelation</td>
<td>Block size vs variogram range</td>
<td>Constrain</td>
</tr><tr><td>Target leakage (direct)</td>
<td>Correlation &gt; 0.99</td>
<td>Block</td>
</tr><tr><td>Target leakage (proxy)</td>
<td>Domain implausibility</td>
<td>Warn</td>
</tr><tr><td>ID/duplicate leakage</td>
<td>Index intersection, hashing</td>
<td>Block</td>
</tr><tr><td>Global feature engineering</td>
<td>Encoding object training data</td>
<td>Block</td>
</tr><tr><td>Threshold on test</td>
<td>Label access in threshold code</td>
<td>Block</td>
</tr><tr><td>Metric cherry-picking</td>
<td>Pre-specification check</td>
<td>Constrain</td>
</tr><tr><td>Stacking double-dip</td>
<td>Data flow tracing</td>
<td>Block</td>
</tr><tr><td>HPO on test data</td>
<td>Index tracing through tuning</td>
<td>Block</td>
</tr><tr><td>Early stopping on test</td>
<td>Callback data source</td>
<td>Block</td>
</tr><tr><td>Preprocessing leak</td>
<td>Parameter origin tracing</td>
<td>Block</td>
</tr></tbody></table><hr></div>
<div class="section level2">
<h2 id="implementation-priority">Implementation Priority<a class="anchor" aria-label="anchor" href="#implementation-priority"></a></h2>
<p><strong>Phase 1 - Hard Violations (Must Block):</strong> 1. Train-test index overlap 2. Preprocessing fitted on full data 3. Target leakage (direct, correlation &gt; 0.99) 4. Temporal look-ahead in features 5. HPO using test data</p>
<p><strong>Phase 2 - Structural Violations (Block or Rewrite):</strong> 1. Group overlap in grouped CV 2. Global feature engineering 3. Threshold optimization on test 4. Early stopping on test 5. Stacking with validation reuse</p>
<p><strong>Phase 3 - Soft Inflation (Constrain and Warn):</strong> 1. Spatial block size vs autocorrelation 2. Embargo vs temporal autocorrelation 3. External validation overlap 4. Subgroup analysis timing 5. Bootstrap estimator assumptions</p>
<hr></div>
<div class="section level2">
<h2 id="r-object-inspection-api-required">R Object Inspection API (Required)<a class="anchor" aria-label="anchor" href="#r-object-inspection-api-required"></a></h2>
<p>BORG must be able to inspect:</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Preprocessing objects</span></span>
<span><span class="fu"><a href="reference/borg_inspect.html">borg_inspect</a></span><span class="op">(</span><span class="va">preProcess_obj</span><span class="op">)</span>     <span class="co"># Extract training data indices</span></span>
<span><span class="fu"><a href="reference/borg_inspect.html">borg_inspect</a></span><span class="op">(</span><span class="va">recipe_obj</span><span class="op">)</span>         <span class="co"># Extract template row count, prep data</span></span>
<span></span>
<span><span class="co"># CV objects</span></span>
<span><span class="fu"><a href="reference/borg_inspect.html">borg_inspect</a></span><span class="op">(</span><span class="va">trainControl_obj</span><span class="op">)</span>   <span class="co"># Extract index, indexOut</span></span>
<span><span class="fu"><a href="reference/borg_inspect.html">borg_inspect</a></span><span class="op">(</span><span class="va">rsample_split</span><span class="op">)</span>      <span class="co"># Extract analysis/assessment indices</span></span>
<span></span>
<span><span class="co"># Model objects</span></span>
<span><span class="fu"><a href="reference/borg_inspect.html">borg_inspect</a></span><span class="op">(</span><span class="va">caret_train</span><span class="op">)</span>        <span class="co"># Extract resampling results, data used</span></span>
<span><span class="fu"><a href="reference/borg_inspect.html">borg_inspect</a></span><span class="op">(</span><span class="va">mlr3_learner</span><span class="op">)</span>       <span class="co"># Extract task data, resampling</span></span>
<span></span>
<span><span class="co"># Feature engineering</span></span>
<span><span class="fu"><a href="reference/borg_inspect.html">borg_inspect</a></span><span class="op">(</span><span class="va">target_encoder</span><span class="op">)</span>     <span class="co"># Extract encoding training data</span></span>
<span><span class="fu"><a href="reference/borg_inspect.html">borg_inspect</a></span><span class="op">(</span><span class="va">pca_object</span><span class="op">)</span>         <span class="co"># Extract training data indices</span></span>
<span></span>
<span><span class="co"># Temporal</span></span>
<span><span class="fu"><a href="reference/borg_inspect.html">borg_inspect</a></span><span class="op">(</span><span class="va">ts_features</span><span class="op">)</span>        <span class="co"># Extract timestamps per feature</span></span>
<span><span class="fu"><a href="reference/borg_inspect.html">borg_inspect</a></span><span class="op">(</span><span class="va">ts_target</span><span class="op">)</span>          <span class="co"># Extract timestamps per target value</span></span></code></pre></div>
<p>Each inspector returns a standardized structure enabling BORG to trace data flow and detect violations.</p>
</div>
</div>

  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside></div>


    <footer><div class="pkgdown-footer-left">
  <p>Developed by <a href="https://github.com/gcol33" class="external-link">Gilles Colling</a>.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.2.0.</p>
</div>

    </footer></div>





  </body></html>

