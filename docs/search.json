[{"path":"https://gillescolling.com/BORG/articles/frameworks.html","id":"base-r","dir":"Articles","previous_headings":"","what":"Base R","title":"Framework Integration","text":"Manual index-based splitting:","code":"library(BORG)  # Create data and split data <- iris set.seed(42) n <- nrow(data) train_idx <- sample(n, 0.7 * n) test_idx <- setdiff(1:n, train_idx)  # Quick validation borg(data, train_idx, test_idx) #> BorgRisk Assessment #> =================== #>  #> Status: VALID (no hard violations) #>   Hard violations:  0 #>   Soft inflations:  0 #>   Train indices:    105 rows #>   Test indices:     45 rows #>   Inspected at:     2026-01-09 10:52:07 #>  #> No risks detected.  # Safe preprocessing (train only) train_data <- data[train_idx, ] train_means <- colMeans(train_data[, 1:4]) train_sds <- apply(train_data[, 1:4], 2, sd)  # Apply to both sets using TRAIN statistics data[, 1:4] <- scale(data[, 1:4], center = train_means, scale = train_sds)"},{"path":"https://gillescolling.com/BORG/articles/frameworks.html","id":"caret","dir":"Articles","previous_headings":"","what":"caret","title":"Framework Integration","text":"Validate trainControl preProcess objects:","code":"library(caret) library(BORG)  data(mtcars) train_idx <- 1:25 test_idx <- 26:32  # BAD: preProcess on full data pp_bad <- preProcess(mtcars[, -1], method = c(\"center\", \"scale\")) borg(pp_bad, train_idx, test_idx, data = mtcars) # Detects preprocessing leak  # GOOD: preProcess on train only pp_good <- preProcess(mtcars[train_idx, -1], method = c(\"center\", \"scale\")) borg(pp_good, train_idx, test_idx, data = mtcars) # No violations  # Check trainControl ctrl <- trainControl(   method = \"cv\",   number = 5,   index = createFolds(mtcars$mpg[train_idx], k = 5) ) borg(ctrl, train_idx, test_idx)"},{"path":"https://gillescolling.com/BORG/articles/frameworks.html","id":"tidymodels-recipes","dir":"Articles","previous_headings":"","what":"tidymodels / recipes","title":"Framework Integration","text":"Validate recipe objects:","code":"library(recipes) library(rsample) library(BORG)  # Use mtcars for reproducible example data(mtcars)  # Create split set.seed(123) split <- initial_split(mtcars, prop = 0.8) train_idx <- split$in_id test_idx <- setdiff(seq_len(nrow(mtcars)), train_idx)  # BAD: recipe prepped on full data rec_bad <- recipe(mpg ~ ., data = mtcars) %>%   step_normalize(all_numeric_predictors()) %>%   prep()  # Uses full mtcars data!  borg(rec_bad, train_idx, test_idx, data = mtcars) # Detects leak  # GOOD: recipe prepped on training only rec_good <- recipe(mpg ~ ., data = training(split)) %>%   step_normalize(all_numeric_predictors()) %>%   prep()  borg(rec_good, train_idx, test_idx, data = mtcars) # Clean"},{"path":"https://gillescolling.com/BORG/articles/frameworks.html","id":"rsample-objects","dir":"Articles","previous_headings":"tidymodels / recipes","what":"rsample Objects","title":"Framework Integration","text":"Inspect resampling schemes: Additional rsample patterns (requires appropriate data):","code":"# Validate v-fold CV (using split from previous chunk) folds <- vfold_cv(training(split), v = 5) borg(folds, train_idx, test_idx) # Validate grouped CV group_folds <- group_vfold_cv(data, group = patient_id, v = 5) borg(group_folds, train_idx, test_idx)  # Validate temporal splits rolling <- sliding_window(ts_data, lookback = 100, assess_stop = 50) borg(rolling, train_idx, test_idx)"},{"path":"https://gillescolling.com/BORG/articles/frameworks.html","id":"mlr3","dir":"Articles","previous_headings":"","what":"mlr3","title":"Framework Integration","text":"Validate tasks resamplings:","code":"library(mlr3) library(BORG)  # Create task task <- TaskClassif$new(\"iris\", iris, target = \"Species\")  # Create resampling resampling <- rsmp(\"cv\", folds = 5) resampling$instantiate(task)  # Inspect train_idx <- resampling$train_set(1) test_idx <- resampling$test_set(1) borg(task, train_idx, test_idx)"},{"path":"https://gillescolling.com/BORG/articles/frameworks.html","id":"temporal-data","dir":"Articles","previous_headings":"","what":"Temporal Data","title":"Framework Integration","text":"time series panel data: Rolling origin validation rsample:","code":"# Create example time series data set.seed(123) n <- 500 ts_data <- data.frame(   date = seq(as.Date(\"2020-01-01\"), by = \"day\", length.out = n),   value = cumsum(rnorm(n)),   feature = rnorm(n) )  train_idx <- 1:252 test_idx <- 253:365  # Validate with temporal ordering check borg(ts_data, train_idx, test_idx, temporal_col = \"date\") #> BorgRisk Assessment #> =================== #>  #> Status: VALID (no hard violations) #>   Hard violations:  0 #>   Soft inflations:  0 #>   Train indices:    252 rows #>   Test indices:     113 rows #>   Inspected at:     2026-01-09 10:52:07 #>  #> No risks detected. rolling <- rolling_origin(   data = ts_data,   initial = 365,   assess = 30,   cumulative = FALSE ) borg(rolling, train_idx = NULL, test_idx = NULL)"},{"path":"https://gillescolling.com/BORG/articles/frameworks.html","id":"spatial-data","dir":"Articles","previous_headings":"","what":"Spatial Data","title":"Framework Integration","text":"spatial cross-validation:","code":"# Create example spatial data set.seed(456) n <- 100 spatial_data <- data.frame(   longitude = runif(n, -10, 10),   latitude = runif(n, -10, 10),   response = rnorm(n),   predictor = rnorm(n) )  # Split by spatial blocks (west vs east) train_idx <- which(spatial_data$longitude < 0) test_idx <- which(spatial_data$longitude >= 0)  # Validate with spatial columns borg(spatial_data, train_idx, test_idx, spatial_cols = c(\"longitude\", \"latitude\")) #> BorgRisk Assessment #> =================== #>  #> Status: VALID (no hard violations) #>   Hard violations:  0 #>   Soft inflations:  0 #>   Train indices:    46 rows #>   Test indices:     54 rows #>   Inspected at:     2026-01-09 10:52:07 #>  #> No risks detected."},{"path":"https://gillescolling.com/BORG/articles/frameworks.html","id":"complete-workflow-validation","dir":"Articles","previous_headings":"","what":"Complete Workflow Validation","title":"Framework Integration","text":"Validate entire pipeline:","code":"# Example workflow with iris data data <- iris set.seed(789) n <- nrow(data) train_idx <- sample(n, 0.7 * n) test_idx <- setdiff(1:n, train_idx)  # Pass a workflow list to borg() result <- borg(list(   data = data,   train_idx = train_idx,   test_idx = test_idx,   target_col = \"Species\" ))  if (!result@is_valid) {   print(result)   message(\"Evaluation invalid - see risk report above\") } #> BorgRisk Assessment #> =================== #>  #> Status: INVALID (hard violations detected) #>   Hard violations:  1 #>   Soft inflations:  0 #>   Train indices:    105 rows #>   Test indices:     45 rows #>   Inspected at:     2026-01-09 10:52:07 #>  #> --- HARD VIOLATIONS (must fix) --- #>  #> [1] duplicate_rows #>     Test set contains 1 rows identical to training rows (memorization risk) #>     Source: data.frame #>     Affected: 102 #> Evaluation invalid - see risk report above"},{"path":"https://gillescolling.com/BORG/articles/frameworks.html","id":"automatic-rewriting","dir":"Articles","previous_headings":"","what":"Automatic Rewriting","title":"Framework Integration","text":"Attempt fix leaky pipelines: Note: violations automatically fixed (e.g., index overlap requires new split).","code":"# Create a workflow with a fixable issue workflow <- list(   data = iris,   train_idx = 1:100,   test_idx = 51:150  # Overlaps with train! )  # Attempt automatic fixes fixed <- borg_rewrite(workflow)  if (length(fixed$unfixable) > 0) {   message(\"Could not fix: \", paste(fixed$unfixable, collapse = \", \")) } #> Could not fix: index_overlap, duplicate_rows"},{"path":"https://gillescolling.com/BORG/articles/quickstart.html","id":"what-is-borg","dir":"Articles","previous_headings":"","what":"What is BORG?","title":"Quick Start","text":"BORG inspects preprocessing model objects detect data leakage. checks whether information test set leaked training, blocks evaluation compute misleading metrics. pass fitted objects borg() checks leakage signatures.","code":""},{"path":"https://gillescolling.com/BORG/articles/quickstart.html","id":"the-problem","dir":"Articles","previous_headings":"","what":"The Problem","title":"Quick Start","text":"Consider common mistake: scale() call used 1000 rows compute mean SD. Test set statistics leaked training data. reported performance won’t match real-world results.","code":"# PROBLEMATIC WORKFLOW data <- read.csv(\"my_data.csv\") data_scaled <- scale(data)  # Fitted on ALL rows  train_idx <- 1:800 test_idx <- 801:1000 train <- data_scaled[train_idx, ] test <- data_scaled[test_idx, ]  model <- train_model(train) performance <- evaluate(model, test)  # Inflated!"},{"path":"https://gillescolling.com/BORG/articles/quickstart.html","id":"how-borg-catches-this","dir":"Articles","previous_headings":"","what":"How BORG Catches This","title":"Quick Start","text":"BORG inspects objects create : BORG detected preProcess fitted rows training set. evaluation blocked compute metrics.","code":"library(BORG)  # You did preprocessing pp <- preProcess(data, method = c(\"center\", \"scale\"))  # Now check it for leakage borg(pp, train_idx = 1:800, test_idx = 801:1000, data = data) # Error: BORG HARD VIOLATION: preprocessing fitted on 1000 rows, but training set has 800"},{"path":"https://gillescolling.com/BORG/articles/quickstart.html","id":"typical-workflow","dir":"Articles","previous_headings":"","what":"Typical Workflow","title":"Quick Start","text":"key point: call borg() objects create , compute metrics.","code":"library(BORG)  # 1. Define your split train_idx <- 1:800 test_idx <- 801:1000  # 2. Do preprocessing on TRAINING ONLY pp <- preProcess(data[train_idx, ], method = c(\"center\", \"scale\"))  # 3. Check the preprocessing object borg(pp, train_idx, test_idx, data = data) # No error - preprocessing is clean  # 4. Fit model on training data model <- train(y ~ ., data = train_data, preProcess = pp)  # 5. Check the model borg(model, train_idx, test_idx, data = data) # No error - model is clean  # 6. Now safe to evaluate predictions <- predict(model, test_data) performance <- compute_metrics(predictions, test_data$y)"},{"path":"https://gillescolling.com/BORG/articles/quickstart.html","id":"what-borg-can-check","dir":"Articles","previous_headings":"","what":"What BORG Can Check","title":"Quick Start","text":"Pass borg():","code":"# Data frame - checks split validity borg(data, train_idx, test_idx)  # Preprocessing object - checks for leakage borg(my_recipe, train_idx, test_idx, data = data) borg(my_prcomp, train_idx, test_idx, data = data)  # Model - checks training data scope borg(my_model, train_idx, test_idx, data = data)  # CV object - checks fold structure borg(my_folds, train_idx, test_idx)"},{"path":"https://gillescolling.com/BORG/articles/quickstart.html","id":"split-validation","dir":"Articles","previous_headings":"","what":"Split Validation","title":"Quick Start","text":"data frames, BORG checks split validity: checks run immediately - object inspection needed.","code":"# Index overlap borg(data, train_idx = 1:60, test_idx = 50:100) # Error: BORG HARD VIOLATION: train_idx and test_idx overlap (11 shared indices)  # Group leakage (same patient in train and test) borg(data, train_idx, test_idx, group_col = \"patient_id\")  # Temporal leakage (test data predates training) borg(data, train_idx, test_idx, temporal_col = \"date\")"},{"path":"https://gillescolling.com/BORG/articles/quickstart.html","id":"risk-classification","dir":"Articles","previous_headings":"","what":"Risk Classification","title":"Quick Start","text":"Hard Violations - Evaluation invalid. Blocked. Index overlap train test Preprocessing fitted full data Target leakage (feature derived outcome) Temporal look-ahead Group membership splits Soft Inflation - Results biased bounded. Warning. Spatial block size autocorrelation range Post-hoc subgroup discovery Proxy leakage (high correlation target)","code":""},{"path":[]},{"path":"https://gillescolling.com/BORG/articles/quickstart.html","id":"next-steps","dir":"Articles","previous_headings":"","what":"Next Steps","title":"Quick Start","text":"Risk Taxonomy: Full catalog detectable risks Framework Integration: Using BORG caret, tidymodels, mlr3","code":""},{"path":"https://gillescolling.com/BORG/articles/risk-taxonomy.html","id":"hard-violations","dir":"Articles","previous_headings":"","what":"Hard Violations","title":"Risk Taxonomy","text":"fundamentally invalidate evaluation. BORG blocks errors detection.","code":""},{"path":"https://gillescolling.com/BORG/articles/risk-taxonomy.html","id":"index-overlap","dir":"Articles","previous_headings":"Hard Violations","what":"1. Index Overlap","title":"Risk Taxonomy","text":": row indices appear training test sets. Detection: Set intersection train_idx test_idx. Example:","code":"train_idx <- 1:60 test_idx <- 50:100  # Rows 50-60 in both!  borg(data, train_idx, test_idx) # Error: BORG HARD VIOLATION: train_idx and test_idx overlap (11 shared indices)"},{"path":"https://gillescolling.com/BORG/articles/risk-taxonomy.html","id":"duplicate-rows","dir":"Articles","previous_headings":"Hard Violations","what":"2. Duplicate Rows","title":"Risk Taxonomy","text":": Test set contains rows identical training rows. Detection: Row hashing comparison. matters: Model may memorized exact patterns.","code":"result <- borg(data, train_idx, test_idx) # risks[[1]]$type == \"duplicate_rows\""},{"path":"https://gillescolling.com/BORG/articles/risk-taxonomy.html","id":"preprocessing-leak","dir":"Articles","previous_headings":"Hard Violations","what":"3. Preprocessing Leak","title":"Risk Taxonomy","text":": Normalization, imputation, PCA fitted full data splitting. Detection: Compare preprocessing parameters train-statistics. Observable signals: preProcess$mean includes test statistics recipe$template rows training set prcomp$center computed full data","code":"# Check a preprocessing object borg(my_recipe, train_idx, test_idx, data = data)"},{"path":"https://gillescolling.com/BORG/articles/risk-taxonomy.html","id":"target-leakage-direct","dir":"Articles","previous_headings":"Hard Violations","what":"4. Target Leakage (Direct)","title":"Risk Taxonomy","text":": Feature correlation > 0.99 target. Detection: Correlation matrix inspection. matters: Feature likely derived outcome (e.g., “days_since_diagnosis” predict “has_disease”).","code":""},{"path":"https://gillescolling.com/BORG/articles/risk-taxonomy.html","id":"temporal-look-ahead","dir":"Articles","previous_headings":"Hard Violations","what":"5. Temporal Look-Ahead","title":"Risk Taxonomy","text":": Features time t contain information time t+k. Detection: Compare feature timestamps prediction timestamps.","code":"# Validate temporal ordering borg(ts_data, train_idx = 1:800, test_idx = 801:1000)"},{"path":"https://gillescolling.com/BORG/articles/risk-taxonomy.html","id":"group-overlap","dir":"Articles","previous_headings":"Hard Violations","what":"6. Group Overlap","title":"Risk Taxonomy","text":": group (patient, site, etc.) appears train test. Detection: Group column value comparison.","code":"# Validate group isolation borg(patient_data, train_idx, test_idx, group_col = \"patient_id\") # Errors if any patient_id in both sets"},{"path":"https://gillescolling.com/BORG/articles/risk-taxonomy.html","id":"global-feature-engineering","dir":"Articles","previous_headings":"Hard Violations","what":"7. Global Feature Engineering","title":"Risk Taxonomy","text":": Target encoding, embeddings, derived features computed full data. Detection: Trace encoding objects training data.","code":""},{"path":"https://gillescolling.com/BORG/articles/risk-taxonomy.html","id":"soft-inflation","dir":"Articles","previous_headings":"","what":"Soft Inflation","title":"Risk Taxonomy","text":"bias results model ranking may preserved. BORG warns.","code":""},{"path":"https://gillescolling.com/BORG/articles/risk-taxonomy.html","id":"spatial-autocorrelation","dir":"Articles","previous_headings":"Soft Inflation","what":"1. Spatial Autocorrelation","title":"Risk Taxonomy","text":": Spatial block size smaller autocorrelation range. Detection: Compare block size parameter variogram estimates. Impact: Nearby test locations leak information training.","code":""},{"path":"https://gillescolling.com/BORG/articles/risk-taxonomy.html","id":"insufficient-embargo","dir":"Articles","previous_headings":"Soft Inflation","what":"2. Insufficient Embargo","title":"Risk Taxonomy","text":": Temporal purge/embargo period shorter autocorrelation decay. Detection: Compare embargo measured serial correlation.","code":""},{"path":"https://gillescolling.com/BORG/articles/risk-taxonomy.html","id":"target-leakage-proxy","dir":"Articles","previous_headings":"Soft Inflation","what":"3. Target Leakage (Proxy)","title":"Risk Taxonomy","text":": Feature correlation 0.95-0.99 target. Detection: Correlation screening domain flagging. warning error: May legitimate strong predictor, requires domain review.","code":""},{"path":"https://gillescolling.com/BORG/articles/risk-taxonomy.html","id":"post-hoc-subgroup-analysis","dir":"Articles","previous_headings":"Soft Inflation","what":"4. Post-hoc Subgroup Analysis","title":"Risk Taxonomy","text":": Subgroups discovered defined seeing test results. Detection: Check subgroup definitions predate evaluation.","code":""},{"path":"https://gillescolling.com/BORG/articles/risk-taxonomy.html","id":"external-validation-overlap","dir":"Articles","previous_headings":"Soft Inflation","what":"5. External Validation Overlap","title":"Risk Taxonomy","text":": “External” dataset shares time/geography/institution training. Detection: Metadata distribution comparison.","code":""},{"path":[]},{"path":"https://gillescolling.com/BORG/articles/risk-taxonomy.html","id":"accessing-risk-details","dir":"Articles","previous_headings":"","what":"Accessing Risk Details","title":"Risk Taxonomy","text":"","code":"result <- borg(object, train_idx, test_idx, data = data)  # Summary result@is_valid result@n_hard result@n_soft  # Individual risks for (risk in result@risks) {   cat(risk$type, \":\", risk$severity, \"\\n\")   cat(\"  \", risk$description, \"\\n\")   if (!is.null(risk$affected_indices)) {     cat(\"  Affected:\", length(risk$affected_indices), \"indices\\n\")   } }  # Tabular format df <- as.data.frame(result)"},{"path":"https://gillescolling.com/BORG/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Gilles Colling. Author, maintainer.","code":""},{"path":"https://gillescolling.com/BORG/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Colling G (2026). BORG: Bounded Outcome Risk Guard Model Evaluation. R package version 0.1.1, https://github.com/gcol33/BORG.","code":"@Manual{,   title = {BORG: Bounded Outcome Risk Guard for Model Evaluation},   author = {Gilles Colling},   year = {2026},   note = {R package version 0.1.1},   url = {https://github.com/gcol33/BORG}, }"},{"path":"https://gillescolling.com/BORG/ENFORCEMENT_SURFACE.html","id":null,"dir":"","previous_headings":"","what":"BORG Enforcement Surface Specification","title":"BORG Enforcement Surface Specification","text":"Version: 1.0.0 Status: Frozen Last Modified: 2025-01-07 document authoritative contract BORG’s enforcement behavior. Changes require rationale entry changelog .","code":""},{"path":[]},{"path":"https://gillescolling.com/BORG/ENFORCEMENT_SURFACE.html","id":"governing-principles","dir":"","previous_headings":"","what":"Governing Principles","title":"BORG Enforcement Surface Specification","text":"BORG gate, linter. Invalid evaluations proceed. Fail closed. Ambiguous cases block rather warn. metrics leave system unless valid. Performance estimates compromised evaluations computed. Actions verbs. Block, Rewrite, Constrain. “Warn” “Inform”. Risk defined outcome layer. Validity conclusions, correctness technique.","code":""},{"path":"https://gillescolling.com/BORG/ENFORCEMENT_SURFACE.html","id":"risk-classification-definitions","dir":"","previous_headings":"","what":"Risk Classification Definitions","title":"BORG Enforcement Surface Specification","text":"Hard Violation: evaluation fundamentally invalid. Results trusted interpretation. BORG must refuse compute must block operation. Soft Inflation: Results biased bounded. Performance estimates misleading may retain ordinal validity (model ranking may preserved). BORG may allow enforced constraints automatic rewriting.","code":""},{"path":[]},{"path":"https://gillescolling.com/BORG/ENFORCEMENT_SURFACE.html","id":"id_11-k-fold-cross-validation","dir":"","previous_headings":"1. Cross-Validation Schemes","what":"1.1 K-Fold Cross-Validation","title":"BORG Enforcement Surface Specification","text":"Observable Signals R: - caret::trainControl objects index/indexOut slots - rsample::vfold_cv objects storing fold assignments - Custom fold vectors integer indices - Preprocessing objects (recipes::recipe, caret::preProcess) fitted splitting Detection Method: - Check preprocessing parameters (mean, sd, PCA loadings) computed full data - Inspect recipe$template row count vs training fold sizes - Compare preProcess$mean fold-specific means Risk Classification: Hard Violation (preprocessing leaks), Soft Inflation (minor statistics leak) Enforcement Action: - Block: preProcess recipe fitted full data fold creation - Rewrite: Inject preprocessing fold’s training pipeline automatically","code":""},{"path":"https://gillescolling.com/BORG/ENFORCEMENT_SURFACE.html","id":"id_12-stratified-k-fold","dir":"","previous_headings":"1. Cross-Validation Schemes","what":"1.2 Stratified K-Fold","title":"BORG Enforcement Surface Specification","text":"Observable Signals R: - caret::createFolds(y, k, list = TRUE) class imbalance - rsample::vfold_cv(strata = ...) specification - Class distribution fold vs natural distribution Detection Method: - Compare class proportions per fold full dataset - Check rare classes artificially balanced across folds - Detect stratification variable temporal/spatial structure Risk Classification: Soft Inflation Enforcement Action: - Allow constraints: Warn class proportions artificially balanced - Flag stratification variable correlates time/space indices","code":""},{"path":"https://gillescolling.com/BORG/ENFORCEMENT_SURFACE.html","id":"id_13-leave-one-out-cross-validation-loocv","dir":"","previous_headings":"1. Cross-Validation Schemes","what":"1.3 Leave-One-Out Cross-Validation (LOOCV)","title":"BORG Enforcement Surface Specification","text":"Observable Signals R: - caret::trainControl(method = \"LOOCV\") - rsample::loo_cv() objects - Fold count equals row count Detection Method: - Check length(folds) == nrow(data) - Detect global preprocessing LOOCV Risk Classification: Hard Violation (preprocessing leak amplified), Soft Inflation (variance estimates unreliable) Enforcement Action: - Block: global preprocessing detected - Allow constraints: Require acknowledgment variance estimates correlated","code":""},{"path":"https://gillescolling.com/BORG/ENFORCEMENT_SURFACE.html","id":"id_14-repeated-cross-validation","dir":"","previous_headings":"1. Cross-Validation Schemes","what":"1.4 Repeated Cross-Validation","title":"BORG Enforcement Surface Specification","text":"Observable Signals R: - caret::trainControl(method = \"repeatedcv\", repeats = n) - Multiple rsample::vfold_cv objects different seeds - Aggregated metrics across repetitions Detection Method: - Check consistent bias direction across repetitions - Detect preprocessing fitted reused across repetitions Risk Classification: Soft Inflation (averaging hides doesn’t fix bias) Enforcement Action: - Allow constraints: Verify repetition independently enforces anti-leakage - Warn stability ≠ validity","code":""},{"path":"https://gillescolling.com/BORG/ENFORCEMENT_SURFACE.html","id":"id_15-nested-cross-validation","dir":"","previous_headings":"1. Cross-Validation Schemes","what":"1.5 Nested Cross-Validation","title":"BORG Enforcement Surface Specification","text":"Observable Signals R: - caret::trainControl search = \"grid\" \"random\" inside outer loop - mlr3::ResamplingNested objects - Inner/outer fold structure tuning results Detection Method: - Trace data flow: outer test indices must appear inner loop computations - Check early stopping criteria outer fold data - Inspect threshold selection data source Risk Classification: Hard Violation (outer fold influences inner loop) Enforcement Action: - Block: outer test data indices appear inner tuning decisions - Rewrite: Enforce strict index separation inner outer loops","code":""},{"path":"https://gillescolling.com/BORG/ENFORCEMENT_SURFACE.html","id":"id_16-group-k-fold--leave-one-group-out","dir":"","previous_headings":"1. Cross-Validation Schemes","what":"1.6 Group K-Fold / Leave-One-Group-Out","title":"BORG Enforcement Surface Specification","text":"Observable Signals R: - caret::groupKFold(group, k) group vector - rsample::group_vfold_cv(group = ...) specification - Group column data frame Detection Method: - Check unique groups train vs test (overlap) - Detect group variable fully captures dependency structure - Test residual within-group correlation features Risk Classification: Hard Violation (groups overlap), Soft Inflation (grouping insufficient) Enforcement Action: - Block: group ID appears train test - Allow constraints: Require grouping variable validated correlation structure","code":""},{"path":[]},{"path":"https://gillescolling.com/BORG/ENFORCEMENT_SURFACE.html","id":"id_21-random-hold-out-split","dir":"","previous_headings":"2. Train-Test Splits","what":"2.1 Random Hold-Out Split","title":"BORG Enforcement Surface Specification","text":"Observable Signals R: - caret::createDataPartition() output - rsample::initial_split() objects - Row indices train/test - .Random.seed state split time Detection Method: - Check split created exploratory analysis - Detect test indices accessed final evaluation - Track call history test set access patterns Risk Classification: Soft Inflation (split timing uncertain) Enforcement Action: - Allow constraints: Require split creation timestamp data exploration - Log test set accesses","code":""},{"path":"https://gillescolling.com/BORG/ENFORCEMENT_SURFACE.html","id":"id_22-multiple-random-splits-with-selection","dir":"","previous_headings":"2. Train-Test Splits","what":"2.2 Multiple Random Splits with Selection","title":"BORG Enforcement Surface Specification","text":"Observable Signals R: - Multiple split objects different seeds - Results object containing metrics multiple splits - Reported metric differs full distribution split metrics Detection Method: - Compare reported metric mean/median across splits - Detect best/worst splits reported - Check selective reporting patterns Risk Classification: Soft Inflation (selective reporting inflates estimates) Enforcement Action: - Allow constraints: Require reporting splits pre-registered single split - Block selective metric reporting","code":""},{"path":"https://gillescolling.com/BORG/ENFORCEMENT_SURFACE.html","id":"id_23-data-snooping-through-iterative-refinement","dir":"","previous_headings":"2. Train-Test Splits","what":"2.3 Data Snooping Through Iterative Refinement","title":"BORG Enforcement Surface Specification","text":"Observable Signals R: - predict() call count test set - Model version history test evaluations interleaved - Incrementing model modifications test evaluation Detection Method: - Count test set evaluation events - Track model object modifications test evaluations - Detect hyperparameters change test feedback Risk Classification: Hard Violation (test set becomes validation set) Enforcement Action: - Block: first test evaluation, refuse evaluations data - Enforce single-use test set policy","code":""},{"path":[]},{"path":"https://gillescolling.com/BORG/ENFORCEMENT_SURFACE.html","id":"id_31-walk-forward--expanding-window-backtest","dir":"","previous_headings":"3. Temporal Evaluation Schemes","what":"3.1 Walk-Forward / Expanding Window Backtest","title":"BORG Enforcement Surface Specification","text":"Observable Signals R: - rsample::sliding_window() / rolling_origin() objects - Time index column data - Feature columns future-derived values Detection Method: - Check feature timestamps prediction timestamps - Detect features contain information t+k predictions t - Validate model time t uses data ≤ t Risk Classification: Hard Violation (look-ahead bias) Enforcement Action: - Block: feature timestamp exceeds prediction timestamp - Rewrite: Automatically filter features respect temporal ordering","code":""},{"path":"https://gillescolling.com/BORG/ENFORCEMENT_SURFACE.html","id":"id_32-rolling-window-backtest","dir":"","previous_headings":"3. Temporal Evaluation Schemes","what":"3.2 Rolling Window Backtest","title":"BORG Enforcement Surface Specification","text":"Observable Signals R: - Fixed window size parameter - Window size selection methodology - Regime change indicators time series Detection Method: - Check window size optimized using future data - Detect regime changes window spans inappropriately - Verify stationarity assumption within windows Risk Classification: Soft Inflation (window size data-snooped) Enforcement Action: - Allow constraints: Require window size pre-specified selected past data ","code":""},{"path":"https://gillescolling.com/BORG/ENFORCEMENT_SURFACE.html","id":"id_33-purged-and-embargoed-cross-validation","dir":"","previous_headings":"3. Temporal Evaluation Schemes","what":"3.3 Purged and Embargoed Cross-Validation","title":"BORG Enforcement Surface Specification","text":"Observable Signals R: - Purge gap parameter (rows removed near boundary) - Embargo period parameter - Autocorrelation structure target/features Detection Method: - Compare embargo period measured autocorrelation decay - Check purge removes serially dependent observations - Validate embargo feature autocorrelation, just target Risk Classification: Soft Inflation (embargo insufficient) Enforcement Action: - Allow constraints: Require embargo ≥ autocorrelation decay length - Warn measured autocorrelation exceeds embargo","code":""},{"path":"https://gillescolling.com/BORG/ENFORCEMENT_SURFACE.html","id":"id_34-point-in-time-feature-construction","dir":"","previous_headings":"3. Temporal Evaluation Schemes","what":"3.4 Point-in-Time Feature Construction","title":"BORG Enforcement Surface Specification","text":"Observable Signals R: - Data vintage timestamps (available) - Revised vs preliminary data indicators - Feature values changed creation date Detection Method: - Check data revision columns - Compare feature values vintage-specific values - Detect anachronistic feature values Risk Classification: Hard Violation (look-ahead revisions) Enforcement Action: - Block: revised data used without vintage timestamps - Require point--time database vintage column","code":""},{"path":[]},{"path":"https://gillescolling.com/BORG/ENFORCEMENT_SURFACE.html","id":"id_41-spatial-cross-validation-block-cv","dir":"","previous_headings":"4. Spatial and Hierarchical Evaluation","what":"4.1 Spatial Cross-Validation (Block CV)","title":"BORG Enforcement Surface Specification","text":"Observable Signals R: - sf spatial objects coordinates - sp::SpatialPoints coordinate data - blockCV spatialsample fold objects - Spatial block size parameter Detection Method: - Compute spatial autocorrelation range (variogram) - Compare block size autocorrelation range - Detect train/test blocks spatially adjacent Risk Classification: Soft Inflation (blocks small) Enforcement Action: - Allow constraints: Require block size ≥ autocorrelation range - Warn spatial leakage detected adjacent blocks","code":""},{"path":"https://gillescolling.com/BORG/ENFORCEMENT_SURFACE.html","id":"id_42-leave-one-location-out-spatial-transfer","dir":"","previous_headings":"4. Spatial and Hierarchical Evaluation","what":"4.2 Leave-One-Location-Out (Spatial Transfer)","title":"BORG Enforcement Surface Specification","text":"Observable Signals R: - Location/site column data - Coordinates per location - Environmental covariates per location Detection Method: - Check spatial separation train test locations - Detect test locations within convex hull training locations - Compare environmental envelopes train vs test Risk Classification: Soft Inflation (interpolation vs extrapolation confusion) Enforcement Action: - Allow constraints: Flag test locations interpolative, extrapolative - Require explicit statement transfer claim scope","code":""},{"path":"https://gillescolling.com/BORG/ENFORCEMENT_SURFACE.html","id":"id_43-clustered-standard-errors-without-clustered-cv","dir":"","previous_headings":"4. Spatial and Hierarchical Evaluation","what":"4.3 Clustered Standard Errors Without Clustered CV","title":"BORG Enforcement Surface Specification","text":"Observable Signals R: - sandwich::vcovCL() clubSandwich usage post-hoc - Cluster variable present used CV splitting - lme4::lmer() random effects without grouped CV Detection Method: - Check cluster variable exists CV ignored - Detect cluster-aware standard errors applied non-clustered CV results Risk Classification: Soft Inflation (point estimates biased, SE correction insufficient) Enforcement Action: - Block: Standard errors non-clustered CV clustered correction - Rewrite: Force cluster-aware CV splitting","code":""},{"path":[]},{"path":"https://gillescolling.com/BORG/ENFORCEMENT_SURFACE.html","id":"id_51-in-silico-validation-with-known-ground-truth","dir":"","previous_headings":"5. Simulation-Based Evaluation","what":"5.1 In-Silico Validation with Known Ground Truth","title":"BORG Enforcement Surface Specification","text":"Observable Signals R: - Simulation function parameters - Model architecture designed knowledge simulation - Simulation--model alignment Detection Method: - Check simulation parameters fixed model development - Detect model architecture exploits known simulation structure - Compare model assumptions simulation assumptions Risk Classification: Soft Inflation (alignment may generalize) Enforcement Action: - Allow constraints: Require simulation parameters pre-specified - Warn model assumptions match simulation assumptions exactly","code":""},{"path":"https://gillescolling.com/BORG/ENFORCEMENT_SURFACE.html","id":"id_52-synthetic-data-augmentation-evaluated-on-real-test-set","dir":"","previous_headings":"5. Simulation-Based Evaluation","what":"5.2 Synthetic Data Augmentation Evaluated on Real Test Set","title":"BORG Enforcement Surface Specification","text":"Observable Signals R: - Synthetic data generator (GAN, SMOTE, etc.) - Generator training data includes test set - Augmented training data contains synthetic samples Detection Method: - Trace generator training data indices - Check generator saw test set augmentation - Validate generator training used train split Risk Classification: Hard Violation (test set information augmented training) Enforcement Action: - Block: generator trained data including test indices - Rewrite: Retrain generator train-data","code":""},{"path":"https://gillescolling.com/BORG/ENFORCEMENT_SURFACE.html","id":"id_53-bootstrap-performance-estimates","dir":"","previous_headings":"5. Simulation-Based Evaluation","what":"5.3 Bootstrap Performance Estimates","title":"BORG Enforcement Surface Specification","text":"Observable Signals R: - boot::boot() results - .632 .632+ estimator specification - Bootstrap sample indices Detection Method: - Check bootstrap estimator assumptions data dimensionality - Detect high-dimensional settings .632 correction fails - Validate --bag samples genuinely independent Risk Classification: Soft Inflation (bias correction may incorrect) Enforcement Action: - Allow constraints: Warn high-dimensional settings - Require explicit acknowledgment estimator assumptions","code":""},{"path":[]},{"path":"https://gillescolling.com/BORG/ENFORCEMENT_SURFACE.html","id":"id_61-target-leakage-direct","dir":"","previous_headings":"6. Target and Feature Leakage Patterns","what":"6.1 Target Leakage (Direct)","title":"BORG Enforcement Surface Specification","text":"Observable Signals R: - Feature names suggesting outcome derivation (“diagnosis_date”, “outcome_indicator”) - Perfect near-perfect correlation feature target - Feature creation timestamp target determination Detection Method: - Scan feature names target-derived patterns - Check feature-target correlations > 0.95 - Validate causal ordering metadata available Risk Classification: Hard Violation (trivial prediction, generalization) Enforcement Action: - Block: feature correlates > 0.99 target - Flag features suspicious names manual review","code":""},{"path":"https://gillescolling.com/BORG/ENFORCEMENT_SURFACE.html","id":"id_62-target-leakage-indirectproxy","dir":"","previous_headings":"6. Target and Feature Leakage Patterns","what":"6.2 Target Leakage (Indirect/Proxy)","title":"BORG Enforcement Surface Specification","text":"Observable Signals R: - Features correlated target confounders - Feature importance concentrated likely proxy variables - Domain-inconsistent feature-target relationships Detection Method: - Check high-importance features plausible causal paths - Detect features proxies group membership - Flag features implausibly strong predictive power Risk Classification: Soft Inflation (may generalize distribution shift) Enforcement Action: - Allow constraints: Require domain validation feature-target relationships - Warn suspiciously powerful features","code":""},{"path":"https://gillescolling.com/BORG/ENFORCEMENT_SURFACE.html","id":"id_63-train-test-leakage-through-identifiers","dir":"","previous_headings":"6. Target and Feature Leakage Patterns","what":"6.3 Train-Test Leakage Through Identifiers","title":"BORG Enforcement Surface Specification","text":"Observable Signals R: - ID columns data (row names, explicit ID column) - Duplicate rows train test - Near-duplicate detection (high similarity train/test rows) Detection Method: - Check duplicate row hashes train/test - Detect shared ID values across splits - Compute nearest-neighbor distances train test Risk Classification: Hard Violation (memorization, learning) Enforcement Action: - Block: ID appears train test - Block: duplicate rows exist across splits - Warn near-duplicates (cosine similarity > 0.99)","code":""},{"path":"https://gillescolling.com/BORG/ENFORCEMENT_SURFACE.html","id":"id_64-leakage-through-global-feature-engineering","dir":"","previous_headings":"6. Target and Feature Leakage Patterns","what":"6.4 Leakage Through Global Feature Engineering","title":"BORG Enforcement Surface Specification","text":"Observable Signals R: - Target encoding computed full data - Frequency statistics full data - Embeddings (word2vec, PCA) fitted full data Detection Method: - Trace feature engineering objects training data - Check encoding/embedding objects used train+test - Validate feature statistics train-statistics Risk Classification: Hard Violation (test statistics training features) Enforcement Action: - Block: feature engineering objects fitted full data - Rewrite: Recompute features within fold using train-data","code":""},{"path":[]},{"path":"https://gillescolling.com/BORG/ENFORCEMENT_SURFACE.html","id":"id_71-threshold-optimization-on-test-data","dir":"","previous_headings":"7. Metric and Threshold Selection","what":"7.1 Threshold Optimization on Test Data","title":"BORG Enforcement Surface Specification","text":"Observable Signals R: - pROC::coords() optimal threshold test ROC - Threshold selection code accessing test labels - Multiple thresholds evaluated test set Detection Method: - Check threshold selection used test labels - Trace threshold value origin train vs test data - Detect threshold optimization loops test data Risk Classification: Hard Violation (threshold model parameter) Enforcement Action: - Block: threshold selected using test labels - Rewrite: Move threshold selection validation set","code":""},{"path":"https://gillescolling.com/BORG/ENFORCEMENT_SURFACE.html","id":"id_72-metric-selection-after-results-are-known","dir":"","previous_headings":"7. Metric and Threshold Selection","what":"7.2 Metric Selection After Results Are Known","title":"BORG Enforcement Surface Specification","text":"Observable Signals R: - Multiple metrics computed, subset reported - Metric choice differs pre-registration () - Primary metric declaration evaluation Detection Method: - Check primary metric declared evaluation - Detect selective metric reporting - Compare reported metrics computed metrics Risk Classification: Soft Inflation (favorable metric selection) Enforcement Action: - Allow constraints: Require pre-specified primary metric - Report computed metrics primary pre-specified","code":""},{"path":"https://gillescolling.com/BORG/ENFORCEMENT_SURFACE.html","id":"id_73-subgroup-analysis-post-hoc","dir":"","previous_headings":"7. Metric and Threshold Selection","what":"7.3 Subgroup Analysis Post Hoc","title":"BORG Enforcement Surface Specification","text":"Observable Signals R: - Subgroup definitions created test evaluation - Subgroup-specific metrics showing heterogeneous performance - Subgroups discovered test set analysis Detection Method: - Check subgroup definitions predate test evaluation - Detect subgroups anomalously good/bad performance - Trace subgroup discovery train vs test data Risk Classification: Soft Inflation (cherry-picking favorable subgroups) Enforcement Action: - Allow constraints: Require subgroup pre-specification discovery train data - Flag post-hoc subgroup analyses","code":""},{"path":[]},{"path":"https://gillescolling.com/BORG/ENFORCEMENT_SURFACE.html","id":"id_81-external-validation-on-overlapping-populations","dir":"","previous_headings":"8. External Validation and Transfer Evaluation","what":"8.1 External Validation on Overlapping Populations","title":"BORG Enforcement Surface Specification","text":"Observable Signals R: - Shared time period, geography, institution datasets - Similar covariate distributions train external - Overlapping collection protocols Detection Method: - Compare covariate distributions (train vs external) - Check metadata overlap time/space/institution - Compute domain shift metrics (MMD, KL divergence) Risk Classification: Soft Inflation (narrow generalization scope) Enforcement Action: - Allow constraints: Require documentation overlap dimensions - Warn external data similar training data","code":""},{"path":"https://gillescolling.com/BORG/ENFORCEMENT_SURFACE.html","id":"id_82-transfer-learning-evaluation-with-shared-pretraining-data","dir":"","previous_headings":"8. External Validation and Transfer Evaluation","what":"8.2 Transfer Learning Evaluation with Shared Pretraining Data","title":"BORG Enforcement Surface Specification","text":"Observable Signals R: - Foundation model unknown pretraining data - Test data potentially pretraining corpus - Zero-shot -shot evaluation common benchmarks Detection Method: - Check known contamination (benchmark data pretraining) - Detect memorization signals (verbatim reproduction) - Validate test data verifiably excluded pretraining Risk Classification: Hard Violation (memorization, transfer) Enforcement Action: - Block: test data known pretraining - Require contamination audit held-test sets","code":""},{"path":"https://gillescolling.com/BORG/ENFORCEMENT_SURFACE.html","id":"id_83-domain-adaptation-with-target-domain-labels","dir":"","previous_headings":"8. External Validation and Transfer Evaluation","what":"8.3 Domain Adaptation with Target Domain Labels","title":"BORG Enforcement Surface Specification","text":"Observable Signals R: - Labeled target domain data used adaptation - target data used adaptation evaluation - held-target domain test set Detection Method: - Check adaptation data overlaps evaluation data - Trace label usage adaptation procedure - Validate separate adaptation vs evaluation splits Risk Classification: Hard Violation (circular evaluation) Enforcement Action: - Block: adaptation evaluation use labeled data - Rewrite: Split target domain adaptation evaluation sets","code":""},{"path":[]},{"path":"https://gillescolling.com/BORG/ENFORCEMENT_SURFACE.html","id":"id_91-stackingblending-with-validation-set-reuse","dir":"","previous_headings":"9. Ensemble and Model Selection Leakage","what":"9.1 Stacking/Blending with Validation Set Reuse","title":"BORG Enforcement Surface Specification","text":"Observable Signals R: - Stacking predictions base models - Meta-learner trained validation predictions - validation set used base model selection meta-learner training Detection Method: - Trace validation data base model selection meta-learner - Check base model hyperparameters selected using data meta-learner - Detect double-dipping validation predictions Risk Classification: Hard Violation (validation set used twice) Enforcement Action: - Block: validation set used base selection meta-training - Rewrite: Create four-way split: base train, base validation, meta train, final test","code":""},{"path":"https://gillescolling.com/BORG/ENFORCEMENT_SURFACE.html","id":"id_92-hyperparameter-optimization-across-full-dataset","dir":"","previous_headings":"9. Ensemble and Model Selection Leakage","what":"9.2 Hyperparameter Optimization Across Full Dataset","title":"BORG Enforcement Surface Specification","text":"Observable Signals R: - caret::train() CV including test data - Grid search results using full dataset - Bayesian optimization test data CV Detection Method: - Check HPO CV indices overlap final test indices - Trace hyperparameter selection data used - Validate HPO nested within train split Risk Classification: Hard Violation (test data influenced hyperparameters) Enforcement Action: - Block: HPO used test data form - Rewrite: Enforce nested CV strict test set isolation","code":""},{"path":"https://gillescolling.com/BORG/ENFORCEMENT_SURFACE.html","id":"id_93-early-stopping-on-test-performance","dir":"","previous_headings":"9. Ensemble and Model Selection Leakage","what":"9.3 Early Stopping on Test Performance","title":"BORG Enforcement Surface Specification","text":"Observable Signals R: - Training history test metrics epoch - keras::EarlyStopping callback test data - Model selection based test metric trajectory Detection Method: - Check early stopping callback data source - Detect test metrics influenced training termination - Validate early stopping used validation (test) data Risk Classification: Hard Violation (test set used model selection) Enforcement Action: - Block: early stopping monitored test metrics - Rewrite: Redirect early stopping separate validation set","code":""},{"path":[]},{"path":"https://gillescolling.com/BORG/ENFORCEMENT_SURFACE.html","id":"id_101-imputation-fitted-on-full-data","dir":"","previous_headings":"10. Preprocessing and Pipeline Leakage","what":"10.1 Imputation Fitted on Full Data","title":"BORG Enforcement Surface Specification","text":"Observable Signals R: - mice::mice() fitted splitting - recipes::step_impute_*() trained full data - caret::preProcess(method = \"medianImpute\") full data Detection Method: - Check imputation model training data - Compare imputation parameters train-statistics - Trace $mean, $median imputation objects Risk Classification: Hard Violation (test statistics imputed training values) Enforcement Action: - Block: imputation fitted train+test - Rewrite: Refit imputation within fold train-data","code":""},{"path":"https://gillescolling.com/BORG/ENFORCEMENT_SURFACE.html","id":"id_102-normalizationscaling-with-test-statistics","dir":"","previous_headings":"10. Preprocessing and Pipeline Leakage","what":"10.2 Normalization/Scaling with Test Statistics","title":"BORG Enforcement Surface Specification","text":"Observable Signals R: - scale() applied full data splitting - caret::preProcess(method = c(\"center\", \"scale\")) full data - recipes::step_normalize() trained full data Detection Method: - Compare scaling parameters train-mean/sd - Check preProcess$mean, preProcess$std fold statistics - Trace normalization parameters training data Risk Classification: Hard Violation (test scale information training) Enforcement Action: - Block: normalization fitted train+test - Rewrite: Compute normalization train, apply frozen test","code":""},{"path":"https://gillescolling.com/BORG/ENFORCEMENT_SURFACE.html","id":"id_103-feature-selection-using-test-labels","dir":"","previous_headings":"10. Preprocessing and Pipeline Leakage","what":"10.3 Feature Selection Using Test Labels","title":"BORG Enforcement Surface Specification","text":"Observable Signals R: - caret::rfe() using full data - Correlation-based selection full data - Boruta similar run splitting Detection Method: - Check feature selection used test labels - Compare selected features train-selection - Trace selection criteria computation data used Risk Classification: Hard Violation (test labels drove feature choice) Enforcement Action: - Block: feature selection used test labels - Rewrite: Perform feature selection within fold train-","code":""},{"path":"https://gillescolling.com/BORG/ENFORCEMENT_SURFACE.html","id":"id_104-dimensionality-reduction-pca-umap-on-full-data","dir":"","previous_headings":"10. Preprocessing and Pipeline Leakage","what":"10.4 Dimensionality Reduction (PCA, UMAP) on Full Data","title":"BORG Enforcement Surface Specification","text":"Observable Signals R: - prcomp() stats::princomp() full data - umap::umap() fitted splitting - recipes::step_pca() trained full data Detection Method: - Compare PCA loadings train-PCA - Check UMAP embedding used test data - Trace dimensionality reduction object training data Risk Classification: Hard Violation (test structure reduced space) Enforcement Action: - Block: dimensionality reduction fitted train+test - Rewrite: Fit reduction train, transform test frozen parameters","code":""},{"path":[]},{"path":"https://gillescolling.com/BORG/ENFORCEMENT_SURFACE.html","id":"implementation-priority","dir":"","previous_headings":"","what":"Implementation Priority","title":"BORG Enforcement Surface Specification","text":"Phase 1 - Hard Violations (Must Block): 1. Train-test index overlap 2. Preprocessing fitted full data 3. Target leakage (direct, correlation > 0.99) 4. Temporal look-ahead features 5. HPO using test data Phase 2 - Structural Violations (Block Rewrite): 1. Group overlap grouped CV 2. Global feature engineering 3. Threshold optimization test 4. Early stopping test 5. Stacking validation reuse Phase 3 - Soft Inflation (Constrain Warn): 1. Spatial block size vs autocorrelation 2. Embargo vs temporal autocorrelation 3. External validation overlap 4. Subgroup analysis timing 5. Bootstrap estimator assumptions","code":""},{"path":"https://gillescolling.com/BORG/ENFORCEMENT_SURFACE.html","id":"r-object-inspection-api-required","dir":"","previous_headings":"","what":"R Object Inspection API (Required)","title":"BORG Enforcement Surface Specification","text":"BORG must able inspect: inspector returns standardized structure enabling BORG trace data flow detect violations.","code":"# Preprocessing objects borg_inspect(preProcess_obj)     # Extract training data indices borg_inspect(recipe_obj)         # Extract template row count, prep data  # CV objects borg_inspect(trainControl_obj)   # Extract index, indexOut borg_inspect(rsample_split)      # Extract analysis/assessment indices  # Model objects borg_inspect(caret_train)        # Extract resampling results, data used borg_inspect(mlr3_learner)       # Extract task data, resampling  # Feature engineering borg_inspect(target_encoder)     # Extract encoding training data borg_inspect(pca_object)         # Extract training data indices  # Temporal borg_inspect(ts_features)        # Extract timestamps per feature borg_inspect(ts_target)          # Extract timestamps per target value"},{"path":"https://gillescolling.com/BORG/index.html","id":"borg","dir":"","previous_headings":"","what":"BORG: Bounded Outcome Risk Guard for Model Evaluation","title":"BORG: Bounded Outcome Risk Guard for Model Evaluation","text":"Bounded Outcome Risk Guard BORG detects invalid model evaluation. identifies information flows test data training, blocks evaluation misleading metrics produced.","code":""},{"path":"https://gillescolling.com/BORG/index.html","id":"why-borg","dir":"","previous_headings":"","what":"Why BORG?","title":"BORG: Bounded Outcome Risk Guard for Model Evaluation","text":"won’t know evaluation broken. code runs fine, metrics look good, publish deploy. Months later find 94% accuracy 70% real data. Princeton meta-analysis found leakage errors 648 published papers across 30 scientific fields. civil war prediction research, correcting leakage revealed “complex ML models perform substantively better decades-old Logistic Regression.” reported gains artifacts. BORG catches errors compute metrics. refuses proceed evaluation invalid.","code":""},{"path":"https://gillescolling.com/BORG/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"BORG: Bounded Outcome Risk Guard for Model Evaluation","text":"","code":"# install.packages(\"remotes\") remotes::install_github(\"gcol33/BORG\")"},{"path":"https://gillescolling.com/BORG/index.html","id":"the-problem","dir":"","previous_headings":"","what":"The Problem","title":"BORG: Bounded Outcome Risk Guard for Model Evaluation","text":"call scale() computed mean standard deviation using 1000 rows. leaks test set information training. reported RMSE won’t match real-world performance.","code":"# This code produces inflated performance estimates data <- read.csv(\"data.csv\") data_scaled <- scale(data[, -1]) train <- data_scaled[1:800, ] test <- data_scaled[801:1000, ] model <- lm(y ~ ., data = train) rmse <- sqrt(mean((test$y - predict(model, test))^2))"},{"path":"https://gillescolling.com/BORG/index.html","id":"the-solution","dir":"","previous_headings":"","what":"The Solution","title":"BORG: Bounded Outcome Risk Guard for Model Evaluation","text":"BORG fails closed. metrics get computed.","code":"library(BORG)  # One function does it all borg(data, train_idx = 1:800, test_idx = 801:1000) # Error: BORG HARD VIOLATION: preprocessing fitted on full data"},{"path":"https://gillescolling.com/BORG/index.html","id":"usage","dir":"","previous_headings":"","what":"Usage","title":"BORG: Bounded Outcome Risk Guard for Model Evaluation","text":"","code":"# Validate a train/test split borg(data, train_idx = 1:800, test_idx = 801:1000)  # Check a preprocessing object borg(my_recipe, train_idx, test_idx, data = data)  # Check a fitted model borg(my_model, train_idx, test_idx, data = data)  # Check a CV object borg(my_folds, train_idx, test_idx)"},{"path":[]},{"path":"https://gillescolling.com/BORG/index.html","id":"risk-classification","dir":"","previous_headings":"","what":"Risk Classification","title":"BORG: Bounded Outcome Risk Guard for Model Evaluation","text":"Hard Violation: Evaluation invalid. Blocked. Train-test index overlap Preprocessing fitted full data Target leakage (feature derived outcome) Temporal look-ahead Group membership splits Soft Inflation: Results biased bounded. Constrained. Spatial block size autocorrelation range Embargo period serial dependence Post-hoc subgroup discovery","code":""},{"path":"https://gillescolling.com/BORG/index.html","id":"design-principles","dir":"","previous_headings":"","what":"Design Principles","title":"BORG: Bounded Outcome Risk Guard for Model Evaluation","text":"BORG gate, linter Fail closed ambiguity metrics computed invalid evaluations Risk defined outcome validity, technique correctness","code":""},{"path":"https://gillescolling.com/BORG/index.html","id":"documentation","dir":"","previous_headings":"","what":"Documentation","title":"BORG: Bounded Outcome Risk Guard for Model Evaluation","text":"Quick Start Risk Taxonomy Framework Integration Enforcement Surface Specification","code":""},{"path":"https://gillescolling.com/BORG/index.html","id":"license","dir":"","previous_headings":"","what":"License","title":"BORG: Bounded Outcome Risk Guard for Model Evaluation","text":"MIT","code":""},{"path":"https://gillescolling.com/BORG/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2025 Gilles Colling Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://gillescolling.com/BORG/reference/as.data.frame.BorgRisk.html","id":null,"dir":"Reference","previous_headings":"","what":"Coerce BorgRisk to Data Frame — as.data.frame.BorgRisk","title":"Coerce BorgRisk to Data Frame — as.data.frame.BorgRisk","text":"Converts BorgRisk object data frame detected risks.","code":""},{"path":"https://gillescolling.com/BORG/reference/as.data.frame.BorgRisk.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Coerce BorgRisk to Data Frame — as.data.frame.BorgRisk","text":"","code":"# S3 method for class 'BorgRisk' as.data.frame(x, row.names = NULL, optional = FALSE, ...)"},{"path":"https://gillescolling.com/BORG/reference/as.data.frame.BorgRisk.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Coerce BorgRisk to Data Frame — as.data.frame.BorgRisk","text":"x BorgRisk object. row.names Optional row names output data frame. optional Logical. Passed data.frame(). ... Additional arguments passed data.frame().","code":""},{"path":"https://gillescolling.com/BORG/reference/as.data.frame.BorgRisk.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Coerce BorgRisk to Data Frame — as.data.frame.BorgRisk","text":"data frame row corresponds detected risk. Columns : type, severity, description, source_object, n_affected.","code":""},{"path":[]},{"path":"https://gillescolling.com/BORG/reference/audit_importance.html","id":null,"dir":"Reference","previous_headings":"","what":"Audit Feature Importance Calculations — audit_importance","title":"Audit Feature Importance Calculations — audit_importance","text":"Detects feature importance (SHAP, permutation importance, etc.) computed using test data, can lead biased feature selection data leakage.","code":""},{"path":"https://gillescolling.com/BORG/reference/audit_importance.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Audit Feature Importance Calculations — audit_importance","text":"","code":"audit_importance(   importance,   data,   train_idx,   test_idx,   method = \"auto\",   model = NULL )"},{"path":"https://gillescolling.com/BORG/reference/audit_importance.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Audit Feature Importance Calculations — audit_importance","text":"importance vector, matrix, data frame importance values. data data used compute importance. train_idx Integer vector training indices. test_idx Integer vector test indices. method Character indicating importance method. One \"shap\", \"permutation\", \"gain\", \"impurity\", \"auto\" (default). model Optional fitted model object additional validation.","code":""},{"path":"https://gillescolling.com/BORG/reference/audit_importance.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Audit Feature Importance Calculations — audit_importance","text":"BorgRisk object audit results.","code":""},{"path":"https://gillescolling.com/BORG/reference/audit_importance.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Audit Feature Importance Calculations — audit_importance","text":"Feature importance computed test data form data leakage : SHAP values computed test data reveal test set structure Permutation importance test data uses test labels Feature selection based test importance leads overfit models function checks data used importance calculation includes test indices flags potential violations.","code":""},{"path":"https://gillescolling.com/BORG/reference/audit_importance.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Audit Feature Importance Calculations — audit_importance","text":"","code":"set.seed(42) data <- data.frame(y = rnorm(100), x1 = rnorm(100), x2 = rnorm(100)) train_idx <- 1:70 test_idx <- 71:100  # Simulate importance values importance <- c(x1 = 0.6, x2 = 0.4)  # Good: importance computed on training data result <- audit_importance(importance, data[train_idx, ], train_idx, test_idx)  # Bad: importance computed on full data (includes test) result_bad <- audit_importance(importance, data, train_idx, test_idx)"},{"path":"https://gillescolling.com/BORG/reference/audit_predictions.html","id":null,"dir":"Reference","previous_headings":"","what":"Audit Predictions for Data Leakage — audit_predictions","title":"Audit Predictions for Data Leakage — audit_predictions","text":"Validates predictions generated correctly without data leakage. Checks predictions correspond test data prediction process use information test set.","code":""},{"path":"https://gillescolling.com/BORG/reference/audit_predictions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Audit Predictions for Data Leakage — audit_predictions","text":"","code":"audit_predictions(   predictions,   train_idx,   test_idx,   actual = NULL,   data = NULL,   model = NULL )"},{"path":"https://gillescolling.com/BORG/reference/audit_predictions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Audit Predictions for Data Leakage — audit_predictions","text":"predictions Vector predictions (numeric factor). train_idx Integer vector training indices. test_idx Integer vector test indices. actual Optional vector actual values comparison. data Optional data frame containing original data. model Optional fitted model object additional checks.","code":""},{"path":"https://gillescolling.com/BORG/reference/audit_predictions.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Audit Predictions for Data Leakage — audit_predictions","text":"BorgRisk object audit results.","code":""},{"path":"https://gillescolling.com/BORG/reference/audit_predictions.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Audit Predictions for Data Leakage — audit_predictions","text":"","code":"# Create data and split set.seed(42) data <- data.frame(y = rnorm(100), x = rnorm(100)) train_idx <- 1:70 test_idx <- 71:100  # Fit model and predict model <- lm(y ~ x, data = data[train_idx, ]) predictions <- predict(model, newdata = data[test_idx, ])  # Audit predictions result <- audit_predictions(predictions, train_idx, test_idx)"},{"path":"https://gillescolling.com/BORG/reference/BORG-package.html","id":null,"dir":"Reference","previous_headings":"","what":"BORG: Bounded Outcome Risk Guard for Model Evaluation — BORG-package","title":"BORG: Bounded Outcome Risk Guard for Model Evaluation — BORG-package","text":"Automatically detects enforces valid model evaluation identifying information reuse training evaluation data. Guards data leakage, look-ahead bias, invalid cross-validation schemes inflate performance estimates. Supports temporal, spatial, grouped evaluation structures. BORG automatically detects enforces valid model evaluation identifying information reuse training evaluation data. guards : Data leakage preprocessing (normalization, imputation, PCA) Look-ahead bias temporal evaluation Spatial autocorrelation violations block CV Target leakage features derived outcomes Train-test contamination shared identifiers","code":""},{"path":"https://gillescolling.com/BORG/reference/BORG-package.html","id":"main-functions","dir":"Reference","previous_headings":"","what":"Main Functions","title":"BORG: Bounded Outcome Risk Guard for Model Evaluation — BORG-package","text":"borg_guard Primary interface guarding evaluation pipelines borg_inspect Inspect R objects leakage signals borg_validate Validate complete evaluation workflow borg_rewrite Automatically rewrite leaky pipelines","code":""},{"path":"https://gillescolling.com/BORG/reference/BORG-package.html","id":"risk-classification","dir":"Reference","previous_headings":"","what":"Risk Classification","title":"BORG: Bounded Outcome Risk Guard for Model Evaluation — BORG-package","text":"BORG classifies evaluation risks : hard_violation Evaluation fundamentally invalid. Must blocked. Examples: preprocessing full data, train-test ID overlap, target leakage. soft_inflation Results biased bounded. Performance estimates misleading model ranking may preserved. Examples: insufficient spatial block size, post-hoc subgroup analysis.","code":""},{"path":"https://gillescolling.com/BORG/reference/BORG-package.html","id":"supported-frameworks","dir":"Reference","previous_headings":"","what":"Supported Frameworks","title":"BORG: Bounded Outcome Risk Guard for Model Evaluation — BORG-package","text":"BORG integrates : caret: trainControl, train, preProcess rsample: vfold_cv, initial_split, rolling_origin recipes: recipe, prep, bake mlr3: Task, Learner, Resampling Base R: manual index-based splitting","code":""},{"path":"https://gillescolling.com/BORG/reference/BORG-package.html","id":"options","dir":"Reference","previous_headings":"","what":"Options","title":"BORG: Bounded Outcome Risk Guard for Model Evaluation — BORG-package","text":"BORG respects following options: borg.auto_check TRUE, automatically validate splits using supported frameworks. Default: FALSE. borg.strict TRUE, throw errors hard violations. FALSE, return warnings. Default: TRUE. borg.verbose TRUE, print diagnostic messages. Default: FALSE.","code":""},{"path":[]},{"path":"https://gillescolling.com/BORG/reference/BORG-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"BORG: Bounded Outcome Risk Guard for Model Evaluation — BORG-package","text":"Maintainer: Gilles Colling gilles.colling051@gmail.com","code":""},{"path":"https://gillescolling.com/BORG/reference/BorgRisk.html","id":null,"dir":"Reference","previous_headings":"","what":"BorgRisk S4 Class — BorgRisk","title":"BorgRisk S4 Class — BorgRisk","text":"Holds result borg_inspect borg_validate: structured assessment evaluation risks detected workflow object. class stores identified risks, classification (hard violation vs soft inflation), affected data indices, recommended remediation actions.","code":""},{"path":"https://gillescolling.com/BORG/reference/BorgRisk.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"BorgRisk S4 Class — BorgRisk","text":"","code":"# S4 method for class 'BorgRisk' show(object)"},{"path":"https://gillescolling.com/BORG/reference/BorgRisk.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"BorgRisk S4 Class — BorgRisk","text":"object BorgRisk object printed.","code":""},{"path":"https://gillescolling.com/BORG/reference/BorgRisk.html","id":"slots","dir":"Reference","previous_headings":"","what":"Slots","title":"BorgRisk S4 Class — BorgRisk","text":"risks list detected risk objects, containing: type Character string: risk category (e.g., \"preprocessing_leak\") severity Character string: \"hard_violation\" \"soft_inflation\" description Character string: human-readable description affected_indices Integer vector: row/column indices affected source_object Character string: name leaky object n_hard Integer. Count hard violations detected. n_soft Integer. Count soft inflation risks detected. is_valid Logical. TRUE hard violations detected. train_indices Integer vector. Row indices training set. test_indices Integer vector. Row indices test set. timestamp POSIXct. inspection performed. call Language object. original call triggered inspection.","code":""},{"path":[]},{"path":"https://gillescolling.com/BORG/reference/BorgRisk.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"BorgRisk S4 Class — BorgRisk","text":"","code":"# Create an empty BorgRisk object (no risks detected) show(new(\"BorgRisk\",   risks = list(),   n_hard = 0L,   n_soft = 0L,   is_valid = TRUE,   train_indices = 1:80,   test_indices = 81:100,   timestamp = Sys.time(),   call = quote(borg_inspect(x)) ))"},{"path":"https://gillescolling.com/BORG/reference/borg_auto_check.html","id":null,"dir":"Reference","previous_headings":"","what":"Enable/Disable BORG Auto-Check Mode — borg_auto_check","title":"Enable/Disable BORG Auto-Check Mode — borg_auto_check","text":"Configures BORG automatically validate train/test splits using supported ML frameworks. enabled, BORG intercept common modeling functions validate indices training proceeds.","code":""},{"path":"https://gillescolling.com/BORG/reference/borg_auto_check.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Enable/Disable BORG Auto-Check Mode — borg_auto_check","text":"","code":"borg_auto_check(enable = TRUE, strict = TRUE, verbose = FALSE)"},{"path":"https://gillescolling.com/BORG/reference/borg_auto_check.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Enable/Disable BORG Auto-Check Mode — borg_auto_check","text":"enable Logical. TRUE, enable auto-check mode. FALSE, disable. strict Logical. TRUE, throw errors violations. FALSE, warn. verbose Logical. TRUE, print diagnostic messages.","code":""},{"path":"https://gillescolling.com/BORG/reference/borg_auto_check.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Enable/Disable BORG Auto-Check Mode — borg_auto_check","text":"Invisibly returns previous state auto-check options.","code":""},{"path":"https://gillescolling.com/BORG/reference/borg_auto_check.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Enable/Disable BORG Auto-Check Mode — borg_auto_check","text":"","code":"# Enable auto-checking with strict mode borg_auto_check(TRUE)  # Disable auto-checking borg_auto_check(FALSE)  # Enable with warnings instead of errors borg_auto_check(TRUE, strict = FALSE)"},{"path":"https://gillescolling.com/BORG/reference/borg_guard.html","id":null,"dir":"Reference","previous_headings":"","what":"Guard Model Evaluation Against Information Reuse — borg_guard","title":"Guard Model Evaluation Against Information Reuse — borg_guard","text":"borg_guard() wraps evaluation workflow enforces valid data handling. intercepts operations leak information test training data either blocks (hard violations) rewrites (soft violations).","code":""},{"path":"https://gillescolling.com/BORG/reference/borg_guard.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Guard Model Evaluation Against Information Reuse — borg_guard","text":"","code":"borg_guard(   data,   train_idx,   test_idx,   mode = c(\"strict\", \"warn\", \"rewrite\"),   temporal_col = NULL,   spatial_cols = NULL,   group_col = NULL )"},{"path":"https://gillescolling.com/BORG/reference/borg_guard.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Guard Model Evaluation Against Information Reuse — borg_guard","text":"data data.frame containing full dataset. train_idx Integer vector training row indices. test_idx Integer vector test row indices. mode Character string specifying enforcement mode: \"strict\": Block violations, refuse proceed \"warn\": Warn violations continue \"rewrite\": Automatically fix violations possible temporal_col Optional character string naming timestamp column. provided, enables temporal ordering validation. spatial_cols Optional character vector naming coordinate columns (e.g., c(\"longitude\", \"latitude\")). provided, enables spatial autocorrelation checks. group_col Optional character string naming grouping column. provided, enables group-level isolation checks.","code":""},{"path":"https://gillescolling.com/BORG/reference/borg_guard.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Guard Model Evaluation Against Information Reuse — borg_guard","text":"borg_context object can used wrap preprocessing evaluation calls. object tracks operations validates train/test split.","code":""},{"path":"https://gillescolling.com/BORG/reference/borg_guard.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Guard Model Evaluation Against Information Reuse — borg_guard","text":"borg_guard() creates guarded context model evaluation. Within context, BORG: Validates initial train/test split Monitors preprocessing operations data leakage Enforces temporal ordering (temporal_col specified) Validates spatial block separation (spatial_cols specified) Ensures group isolation (group_col specified)","code":""},{"path":"https://gillescolling.com/BORG/reference/borg_guard.html","id":"enforcement-modes","dir":"Reference","previous_headings":"","what":"Enforcement Modes","title":"Guard Model Evaluation Against Information Reuse — borg_guard","text":"strict conservative. detected violation causes immediate error. Use production pipelines validity critical. warn Permissive mode. Violations generate warnings evaluation proceeds. Use exploratory analysis legacy code auditing. rewrite Automatic correction mode. BORG attempts fix violations (e.g., refitting preprocessing train-). Use migrating existing pipelines.","code":""},{"path":[]},{"path":"https://gillescolling.com/BORG/reference/borg_guard.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Guard Model Evaluation Against Information Reuse — borg_guard","text":"","code":"# The canonical failure: preprocessing before splitting # This workflow produces inflated performance estimates: # #   data_scaled <- scale(full_data) #   train <- data_scaled[1:800, ] #   test <- data_scaled[801:1000, ] # # BORG blocks this pattern.  # Valid split (no overlap) data <- data.frame(x = rnorm(100), y = rnorm(100)) ctx <- borg_guard(data, train_idx = 1:70, test_idx = 71:100) print(ctx)  # Invalid split (overlap) - errors immediately if (FALSE) { # \\dontrun{ ctx <- borg_guard(data, train_idx = 1:60, test_idx = 50:100) # Error: BORG HARD VIOLATION: train_idx and test_idx overlap } # }  # Grouped data - ensures no group appears in both splits data$patient <- rep(1:10, each = 10) ctx <- borg_guard(   data,   train_idx = 1:50,   test_idx = 51:100,   group_col = \"patient\" )  # Temporal data - validates chronological ordering data$date <- seq.Date(as.Date(\"2020-01-01\"), by = \"day\", length.out = 100) ctx <- borg_guard(   data,   train_idx = 1:70,   test_idx = 71:100,   temporal_col = \"date\" )"},{"path":"https://gillescolling.com/BORG/reference/borg_inspect.html","id":null,"dir":"Reference","previous_headings":"","what":"Inspect R Objects for Evaluation Risks — borg_inspect","title":"Inspect R Objects for Evaluation Risks — borg_inspect","text":"borg_inspect() examines R objects signals information reuse invalidate model evaluation. returns structured assessment detected risks.","code":""},{"path":"https://gillescolling.com/BORG/reference/borg_inspect.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Inspect R Objects for Evaluation Risks — borg_inspect","text":"","code":"borg_inspect(   object,   train_idx = NULL,   test_idx = NULL,   data = NULL,   target_col = NULL,   spatial_cols = NULL,   ... )"},{"path":"https://gillescolling.com/BORG/reference/borg_inspect.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Inspect R Objects for Evaluation Risks — borg_inspect","text":"object R object inspect. Supported types include: Preprocessing: preProcess, recipe, prcomp CV objects: trainControl, rsplit, vfold_cv Model objects: train, lm, glm Data frames train/test split information train_idx Integer vector training row indices. Required data-level inspection. test_idx Integer vector test row indices. Required data-level inspection. data Optional data frame. Required inspecting preprocessing objects compare parameters train-statistics. target_col Optional name target/outcome column. provided, checks target leakage (features highly correlated target). spatial_cols Optional character vector coordinate column names. provided, checks spatial separation train test. ... Additional arguments passed type-specific inspectors.","code":""},{"path":"https://gillescolling.com/BORG/reference/borg_inspect.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Inspect R Objects for Evaluation Risks — borg_inspect","text":"BorgRisk object containing: risks List detected risk objects n_hard Count hard violations n_soft Count soft inflation warnings is_valid TRUE hard violations detected","code":""},{"path":"https://gillescolling.com/BORG/reference/borg_inspect.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Inspect R Objects for Evaluation Risks — borg_inspect","text":"borg_inspect() dispatches type-specific inspectors based class input object. inspector looks specific leakage patterns: Preprocessing objects Checks parameters (mean, sd, loadings) computed data includes test indices CV objects Validates train/test indices overlap grouping structure respected Feature engineering Checks encodings, embeddings, derived features used test data computation","code":""},{"path":[]},{"path":"https://gillescolling.com/BORG/reference/borg_inspect.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Inspect R Objects for Evaluation Risks — borg_inspect","text":"","code":"# Inspect a preprocessing object data(mtcars) train_idx <- 1:25 test_idx <- 26:32  # BAD: preProcess fitted on full data (will detect leak) pp_bad <- scale(mtcars[, -1])  # GOOD: preProcess fitted on train only pp_good <- scale(mtcars[train_idx, -1])"},{"path":"https://gillescolling.com/BORG/reference/borg_options.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Current BORG Options — borg_options","title":"Get Current BORG Options — borg_options","text":"Returns current state BORG configuration options.","code":""},{"path":"https://gillescolling.com/BORG/reference/borg_options.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Current BORG Options — borg_options","text":"","code":"borg_options()"},{"path":"https://gillescolling.com/BORG/reference/borg_options.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Current BORG Options — borg_options","text":"named list current BORG options.","code":""},{"path":"https://gillescolling.com/BORG/reference/borg_options.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get Current BORG Options — borg_options","text":"","code":"borg_options()"},{"path":"https://gillescolling.com/BORG/reference/borg_rewrite.html","id":null,"dir":"Reference","previous_headings":"","what":"Automatically Rewrite Leaky Evaluation Pipelines — borg_rewrite","title":"Automatically Rewrite Leaky Evaluation Pipelines — borg_rewrite","text":"borg_rewrite() attempts automatically fix detected evaluation risks restructuring pipeline avoid information leakage.","code":""},{"path":"https://gillescolling.com/BORG/reference/borg_rewrite.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Automatically Rewrite Leaky Evaluation Pipelines — borg_rewrite","text":"","code":"borg_rewrite(workflow, risks = NULL, fix = \"all\")"},{"path":"https://gillescolling.com/BORG/reference/borg_rewrite.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Automatically Rewrite Leaky Evaluation Pipelines — borg_rewrite","text":"workflow list containing evaluation workflow (structure borg_validate). risks Optional BorgRisk object previous inspection. NULL, borg_validate() called first. fix Character vector specifying risk types attempt fix. Default: \"\" attempts rewritable violations. options: \"preprocessing\", \"feature_engineering\", \"thresholds\".","code":""},{"path":"https://gillescolling.com/BORG/reference/borg_rewrite.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Automatically Rewrite Leaky Evaluation Pipelines — borg_rewrite","text":"list containing: workflow rewritten workflow (modified place possible) fixed Character vector risk types successfully fixed unfixable Character vector risk types fixed report BorgRisk object post-rewrite validation","code":""},{"path":"https://gillescolling.com/BORG/reference/borg_rewrite.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Automatically Rewrite Leaky Evaluation Pipelines — borg_rewrite","text":"borg_rewrite() can automatically fix certain types leakage: Preprocessing full data Refits preprocessing objects using training indices Feature engineering leaks Recomputes target encodings, embeddings, derived features using train-data Threshold optimization Moves threshold selection training/validation data violations automatically fixed: Train-test index overlap (requires new split) Target leakage original features (requires domain intervention) Temporal look-ahead features (requires feature re-engineering)","code":""},{"path":[]},{"path":"https://gillescolling.com/BORG/reference/borg_rewrite.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Automatically Rewrite Leaky Evaluation Pipelines — borg_rewrite","text":"","code":"if (FALSE) { # \\dontrun{ # Attempt to fix a leaky workflow result <- borg_rewrite(my_workflow)  if (length(result$unfixable) > 0) {   warning(\"Some risks could not be automatically fixed\")   print(result$unfixable) }  # Use the fixed workflow fixed_workflow <- result$workflow } # }"},{"path":"https://gillescolling.com/BORG/reference/borg_validate.html","id":null,"dir":"Reference","previous_headings":"","what":"Validate Complete Evaluation Workflow — borg_validate","title":"Validate Complete Evaluation Workflow — borg_validate","text":"borg_validate() performs post-hoc validation entire evaluation workflow, checking components information leakage.","code":""},{"path":"https://gillescolling.com/BORG/reference/borg_validate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Validate Complete Evaluation Workflow — borg_validate","text":"","code":"borg_validate(workflow, strict = FALSE)"},{"path":"https://gillescolling.com/BORG/reference/borg_validate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Validate Complete Evaluation Workflow — borg_validate","text":"workflow list containing evaluation workflow components: data full dataset train_idx Integer vector training indices test_idx Integer vector test indices preprocess Optional preprocessing object(s) model fitted model object predictions Model predictions test data metrics Computed evaluation metrics strict Logical. TRUE, hard violation causes error. Default: FALSE (returns report ).","code":""},{"path":"https://gillescolling.com/BORG/reference/borg_validate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Validate Complete Evaluation Workflow — borg_validate","text":"BorgRisk object containing comprehensive assessment workflow.","code":""},{"path":"https://gillescolling.com/BORG/reference/borg_validate.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Validate Complete Evaluation Workflow — borg_validate","text":"borg_validate() inspects component evaluation workflow: Split validation: Checks train/test index isolation Preprocessing audit: Traces preprocessing parameters verify train-origin Feature audit: Checks target leakage proxy features Model audit: Validates model used training data Threshold audit: Checks thresholds optimized test data","code":""},{"path":[]},{"path":"https://gillescolling.com/BORG/reference/borg_validate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Validate Complete Evaluation Workflow — borg_validate","text":"","code":"if (FALSE) { # \\dontrun{ # Validate an existing workflow result <- borg_validate(list(   data = my_data,   train_idx = train_idx,   test_idx = test_idx,   preprocess = my_recipe,   model = my_model,   predictions = preds,   metrics = list(rmse = 0.5, mae = 0.3) ))  # Check validity if (!result@is_valid) {   print(result)  # Shows detailed risk report } } # }"},{"path":"https://gillescolling.com/BORG/reference/cv_leakage_report.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate CV Leakage Report — cv_leakage_report","title":"Generate CV Leakage Report — cv_leakage_report","text":"Generates detailed report cross-validation leakage issues.","code":""},{"path":"https://gillescolling.com/BORG/reference/cv_leakage_report.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate CV Leakage Report — cv_leakage_report","text":"","code":"cv_leakage_report(cv_object, train_idx, test_idx)"},{"path":"https://gillescolling.com/BORG/reference/cv_leakage_report.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate CV Leakage Report — cv_leakage_report","text":"cv_object cross-validation object (trainControl, vfold_cv, etc.). train_idx Integer vector training indices. test_idx Integer vector test indices.","code":""},{"path":"https://gillescolling.com/BORG/reference/cv_leakage_report.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate CV Leakage Report — cv_leakage_report","text":"list detailed CV leakage information.","code":""},{"path":"https://gillescolling.com/BORG/reference/cv_leakage_report.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate CV Leakage Report — cv_leakage_report","text":"","code":"# Using caret trainControl if (requireNamespace(\"caret\", quietly = TRUE)) {   folds <- list(Fold1 = 1:10, Fold2 = 11:20, Fold3 = 21:25)   ctrl <- caret::trainControl(method = \"cv\", index = folds)   report <- cv_leakage_report(ctrl, train_idx = 1:25, test_idx = 26:32)   print(report) }"},{"path":"https://gillescolling.com/BORG/reference/plot_groups.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Group-Based Split — plot_groups","title":"Plot Group-Based Split — plot_groups","text":"Visualizes group membership train/test assignment, highlighting groups appear sets (group leakage).","code":""},{"path":"https://gillescolling.com/BORG/reference/plot_groups.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Group-Based Split — plot_groups","text":"","code":"plot_groups(   groups,   train_idx,   test_idx,   title = \"Group-Based Split\",   max_groups = 20 )"},{"path":"https://gillescolling.com/BORG/reference/plot_groups.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Group-Based Split — plot_groups","text":"groups Vector group assignments observation. train_idx Integer vector training indices. test_idx Integer vector test indices. title Plot title. max_groups Maximum number groups display (readability).","code":""},{"path":"https://gillescolling.com/BORG/reference/plot_groups.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Group-Based Split — plot_groups","text":"base R plot (invisibly returns NULL).","code":""},{"path":"https://gillescolling.com/BORG/reference/plot_groups.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Group-Based Split — plot_groups","text":"","code":"# Create grouped data groups <- rep(paste0(\"Patient_\", 1:10), each = 10) train_idx <- which(groups %in% paste0(\"Patient_\", 1:7)) test_idx <- which(groups %in% paste0(\"Patient_\", 8:10)) plot_groups(groups, train_idx, test_idx)  # With group leakage train_idx_bad <- 1:70 test_idx_bad <- 61:100  # Overlaps with Patient_7 plot_groups(groups, train_idx_bad, test_idx_bad)"},{"path":"https://gillescolling.com/BORG/reference/plot_risk.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Risk Assessment Summary — plot_risk","title":"Plot Risk Assessment Summary — plot_risk","text":"Visualizes risks detected BORG validation.","code":""},{"path":"https://gillescolling.com/BORG/reference/plot_risk.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Risk Assessment Summary — plot_risk","text":"","code":"plot_risk(risk, title = \"BORG Risk Assessment\", max_risks = 10)"},{"path":"https://gillescolling.com/BORG/reference/plot_risk.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Risk Assessment Summary — plot_risk","text":"risk BorgRisk object borg_inspect, borg_validate, borg_guard. title Plot title. max_risks Maximum number risks display.","code":""},{"path":"https://gillescolling.com/BORG/reference/plot_risk.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Risk Assessment Summary — plot_risk","text":"base R plot (invisibly returns NULL).","code":""},{"path":"https://gillescolling.com/BORG/reference/plot_risk.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Risk Assessment Summary — plot_risk","text":"","code":"data <- data.frame(x = 1:100, y = 101:200) result <- borg_inspect(data, train_idx = 1:60, test_idx = 51:100) plot_risk(result)"},{"path":"https://gillescolling.com/BORG/reference/plot_spatial.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Spatial Split — plot_spatial","title":"Plot Spatial Split — plot_spatial","text":"Visualizes spatial train/test distribution.","code":""},{"path":"https://gillescolling.com/BORG/reference/plot_spatial.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Spatial Split — plot_spatial","text":"","code":"plot_spatial(x, y, train_idx, test_idx, title = \"Spatial Split\")"},{"path":"https://gillescolling.com/BORG/reference/plot_spatial.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Spatial Split — plot_spatial","text":"x Numeric vector x-coordinates (e.g., longitude). y Numeric vector y-coordinates (e.g., latitude). train_idx Integer vector training indices. test_idx Integer vector test indices. title Plot title.","code":""},{"path":"https://gillescolling.com/BORG/reference/plot_spatial.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Spatial Split — plot_spatial","text":"base R plot (invisibly returns NULL).","code":""},{"path":"https://gillescolling.com/BORG/reference/plot_spatial.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Spatial Split — plot_spatial","text":"","code":"set.seed(42) x <- runif(100, -10, 10) y <- runif(100, -10, 10) train_idx <- which(x < 0) test_idx <- which(x >= 0) plot_spatial(x, y, train_idx, test_idx)"},{"path":"https://gillescolling.com/BORG/reference/plot_split.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Train/Test Split Distribution — plot_split","title":"Plot Train/Test Split Distribution — plot_split","text":"Visualizes distribution training test indices, optionally highlighting temporal group structure.","code":""},{"path":"https://gillescolling.com/BORG/reference/plot_split.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Train/Test Split Distribution — plot_split","text":"","code":"plot_split(   train_idx,   test_idx,   n_total = NULL,   temporal = NULL,   groups = NULL,   title = \"Train/Test Split\" )"},{"path":"https://gillescolling.com/BORG/reference/plot_split.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Train/Test Split Distribution — plot_split","text":"train_idx Integer vector training indices. test_idx Integer vector test indices. n_total Total number observations. NULL, inferred indices. temporal Optional numeric/Date vector temporal ordering. groups Optional vector group assignments. title Plot title.","code":""},{"path":"https://gillescolling.com/BORG/reference/plot_split.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Train/Test Split Distribution — plot_split","text":"base R plot (invisibly returns NULL).","code":""},{"path":"https://gillescolling.com/BORG/reference/plot_split.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Train/Test Split Distribution — plot_split","text":"","code":"train_idx <- 1:70 test_idx <- 71:100 plot_split(train_idx, test_idx)  # With temporal structure dates <- seq(as.Date(\"2020-01-01\"), by = \"day\", length.out = 100 ) plot_split(train_idx, test_idx, temporal = dates)"},{"path":"https://gillescolling.com/BORG/reference/plot_temporal.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Temporal Validation — plot_temporal","title":"Plot Temporal Validation — plot_temporal","text":"Visualizes temporal train/test split gap analysis.","code":""},{"path":"https://gillescolling.com/BORG/reference/plot_temporal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Temporal Validation — plot_temporal","text":"","code":"plot_temporal(temporal, train_idx, test_idx, title = \"Temporal Split\")"},{"path":"https://gillescolling.com/BORG/reference/plot_temporal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Temporal Validation — plot_temporal","text":"temporal Numeric Date vector timestamps. train_idx Integer vector training indices. test_idx Integer vector test indices. title Plot title.","code":""},{"path":"https://gillescolling.com/BORG/reference/plot_temporal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Temporal Validation — plot_temporal","text":"base R plot (invisibly returns NULL).","code":""},{"path":"https://gillescolling.com/BORG/reference/plot_temporal.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Temporal Validation — plot_temporal","text":"","code":"dates <- seq(as.Date(\"2020-01-01\"), by = \"day\", length.out = 100) train_idx <- 1:70 test_idx <- 71:100 plot_temporal(dates, train_idx, test_idx)"},{"path":"https://gillescolling.com/BORG/reference/print.borg_context.html","id":null,"dir":"Reference","previous_headings":"","what":"Print method for borg_context — print.borg_context","title":"Print method for borg_context — print.borg_context","text":"Print method borg_context","code":""},{"path":"https://gillescolling.com/BORG/reference/print.borg_context.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print method for borg_context — print.borg_context","text":"","code":"# S3 method for class 'borg_context' print(x, ...)"},{"path":"https://gillescolling.com/BORG/reference/print.borg_context.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print method for borg_context — print.borg_context","text":"x borg_context object ... Additional arguments (ignored)","code":""},{"path":"https://gillescolling.com/BORG/reference/print.borg_cv_report.html","id":null,"dir":"Reference","previous_headings":"","what":"Print CV Leakage Report — print.borg_cv_report","title":"Print CV Leakage Report — print.borg_cv_report","text":"Print CV Leakage Report","code":""},{"path":"https://gillescolling.com/BORG/reference/print.borg_cv_report.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print CV Leakage Report — print.borg_cv_report","text":"","code":"# S3 method for class 'borg_cv_report' print(x, ...)"},{"path":"https://gillescolling.com/BORG/reference/print.borg_cv_report.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print CV Leakage Report — print.borg_cv_report","text":"x borg_cv_report object. ... Additional arguments (ignored).","code":""},{"path":[]},{"path":"https://gillescolling.com/BORG/TODO.html","id":"completed","dir":"","previous_headings":"","what":"Completed","title":"BORG v0.2.0 TODO","text":"Add plot_groups() visualization function Update NEWS.md v0.1.0 features Rebuild pkgdown site Feature importance audit (audit_importance()) tidymodels tune integration (tune_results inspector) CRAN preparation (0 errors, 0 warnings, 0 notes)","code":""},{"path":"https://gillescolling.com/BORG/TODO.html","id":"feature-improvements","dir":"","previous_headings":"","what":"Feature Improvements","title":"BORG v0.2.0 TODO","text":"Improved borg_rewrite() automatic fixes Add suggested fixes risk reports","code":""},{"path":"https://gillescolling.com/BORG/TODO.html","id":"integrations","dir":"","previous_headings":"","what":"Integrations","title":"BORG v0.2.0 TODO","text":"Framework hooks (options(borg.auto_check = TRUE)) MLOps logging (mlflow, vetiver)","code":""},{"path":"https://gillescolling.com/BORG/TODO.html","id":"future","dir":"","previous_headings":"","what":"Future","title":"BORG v0.2.0 TODO","text":"Shiny dashboard interactive exploration CRAN submission","code":""},{"path":[]},{"path":[]},{"path":"https://gillescolling.com/BORG/news/index.html","id":"visualization-functions-0-2-0","dir":"Changelog","previous_headings":"New features","what":"Visualization functions","title":"BORG 0.2.0 (development)","text":"plot_split(): Visualize train/test split distribution temporal group structure plot_risk(): Display risk assessment results horizontal bar chart plot_temporal(): Timeline visualization gap analysis look-ahead detection plot_spatial(): Spatial split visualization convex hulls plot_groups(): Group-based split visualization leakage highlighting","code":""},{"path":"https://gillescolling.com/BORG/news/index.html","id":"model-inspection-0-2-0","dir":"Changelog","previous_headings":"New features","what":"Model inspection","title":"BORG 0.2.0 (development)","text":"lm glm models (checks data used fitting) ranger random forest models xgboost models lightgbm models parsnip model fits workflow objects (tidymodels)","code":""},{"path":"https://gillescolling.com/BORG/news/index.html","id":"audit-functions-0-2-0","dir":"Changelog","previous_headings":"New features","what":"Audit functions","title":"BORG 0.2.0 (development)","text":"audit_predictions(): Validate prediction vectors expected indices cv_leakage_report(): Generate detailed cross-validation leakage reports audit_importance(): Detect feature importance computed test data (SHAP, permutation)","code":""},{"path":"https://gillescolling.com/BORG/news/index.html","id":"tidymodels-integration-0-2-0","dir":"Changelog","previous_headings":"New features","what":"Tidymodels integration","title":"BORG 0.2.0 (development)","text":"Added tune_results inspection tidymodels tuning objects Detects hyperparameter tuning uses test data resamples","code":""},{"path":"https://gillescolling.com/BORG/news/index.html","id":"configuration-0-2-0","dir":"Changelog","previous_headings":"New features","what":"Configuration","title":"BORG 0.2.0 (development)","text":"Added borg_auto_check() enable/disable automatic validation Added borg_options() query current configuration New options: borg.auto_check, borg.strict, borg.verbose","code":""},{"path":"https://gillescolling.com/BORG/news/index.html","id":"bug-fixes-0-2-0","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"BORG 0.2.0 (development)","text":"Fixed rsample vfold_cv inspection attribute structure changes","code":""},{"path":"https://gillescolling.com/BORG/news/index.html","id":"borg-010","dir":"Changelog","previous_headings":"","what":"BORG 0.1.0","title":"BORG 0.1.0","text":"Initial release.","code":""},{"path":"https://gillescolling.com/BORG/news/index.html","id":"core-functionality-0-1-0","dir":"Changelog","previous_headings":"","what":"Core functionality","title":"BORG 0.1.0","text":"borg_guard(): Creates validation context train/test splits support temporal, spatial, grouped structures Index overlap detection Duplicate row detection Target leakage detection (suspicious naming, perfect separation) Feature engineering leakage (global standardization, rank features) Threshold selection leakage Spatial autocorrelation checks HPO validation checks (test data usage, non-nested CV) caret preProcess objects caret trainControl objects tidymodels recipe objects prcomp PCA objects rsample resampling objects borg_rewrite(): Attempts automatic fixes detected violations BorgRisk S4 class structured risk assessment reports","code":""},{"path":"https://gillescolling.com/BORG/news/index.html","id":"performance-0-1-0","dir":"Changelog","previous_headings":"","what":"Performance","title":"BORG 0.1.0","text":"C++ backends via Rcpp fast hash-based index overlap duplicate detection","code":""},{"path":"https://gillescolling.com/BORG/news/index.html","id":"framework-integration-0-1-0","dir":"Changelog","previous_headings":"","what":"Framework integration","title":"BORG 0.1.0","text":"caret: preProcess, trainControl, train objects tidymodels: recipe, rsplit, vfold_cv, rset objects mlr3: task resampling validation Base R: manual index-based splits","code":""}]
