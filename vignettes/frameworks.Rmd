---
title: "Framework Integration"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Framework Integration}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  eval = TRUE
)

# Check package availability
has_caret <- requireNamespace("caret", quietly = TRUE)
has_recipes <- requireNamespace("recipes", quietly = TRUE)
has_rsample <- requireNamespace("rsample", quietly = TRUE)
has_mlr3 <- requireNamespace("mlr3", quietly = TRUE)
has_sf <- requireNamespace("sf", quietly = TRUE)
```

BORG integrates with major R machine learning frameworks. This guide shows
how to validate workflows in each ecosystem.

## Base R

Manual index-based splitting:

```{r}
library(BORG)

# Create data and split
data <- iris
set.seed(42)
n <- nrow(data)
train_idx <- sample(n, 0.7 * n)
test_idx <- setdiff(1:n, train_idx)

# Quick validation
borg(data, train_idx, test_idx)

# Safe preprocessing (train only)
train_data <- data[train_idx, ]
train_means <- colMeans(train_data[, 1:4])
train_sds <- apply(train_data[, 1:4], 2, sd)

# Apply to both sets using TRAIN statistics
data[, 1:4] <- scale(data[, 1:4], center = train_means, scale = train_sds)
```

## caret

Validate `trainControl` and `preProcess` objects:

```{r, eval = has_caret}
library(caret)
library(BORG)

data(mtcars)
train_idx <- 1:25
test_idx <- 26:32

# BAD: preProcess on full data
pp_bad <- preProcess(mtcars[, -1], method = c("center", "scale"))
borg(pp_bad, train_idx, test_idx, data = mtcars)
# Detects preprocessing leak

# GOOD: preProcess on train only
pp_good <- preProcess(mtcars[train_idx, -1], method = c("center", "scale"))
borg(pp_good, train_idx, test_idx, data = mtcars)
# No violations

# Check trainControl
ctrl <- trainControl(
  method = "cv",
  number = 5,
  index = createFolds(mtcars$mpg[train_idx], k = 5)
)
borg(ctrl, train_idx, test_idx)
```

## tidymodels / recipes

Validate recipe objects:

```{r, eval = has_recipes && has_rsample}
library(recipes)
library(rsample)
library(BORG)

# Use mtcars for reproducible example
data(mtcars)

# Create split
set.seed(123)
split <- initial_split(mtcars, prop = 0.8)
train_idx <- split$in_id
test_idx <- setdiff(seq_len(nrow(mtcars)), train_idx)

# BAD: recipe prepped on full data
rec_bad <- recipe(mpg ~ ., data = mtcars) %>%
  step_normalize(all_numeric_predictors()) %>%
  prep()  # Uses full mtcars data!

borg(rec_bad, train_idx, test_idx, data = mtcars)
# Detects leak

# GOOD: recipe prepped on training only
rec_good <- recipe(mpg ~ ., data = training(split)) %>%
  step_normalize(all_numeric_predictors()) %>%
  prep()

borg(rec_good, train_idx, test_idx, data = mtcars)
# Clean
```

### rsample Objects

Inspect resampling schemes:

```{r, eval = has_rsample && has_recipes}
# Validate v-fold CV (using split from previous chunk)
folds <- vfold_cv(training(split), v = 5)
borg(folds, train_idx, test_idx)
```

Additional rsample patterns (requires appropriate data):

```{r, eval = FALSE}
# Validate grouped CV
group_folds <- group_vfold_cv(data, group = patient_id, v = 5)
borg(group_folds, train_idx, test_idx)

# Validate temporal splits
rolling <- sliding_window(ts_data, lookback = 100, assess_stop = 50)
borg(rolling, train_idx, test_idx)
```

## mlr3

Validate tasks and resamplings:

```{r, eval = has_mlr3}
library(mlr3)
library(BORG)

# Create task
task <- TaskClassif$new("iris", iris, target = "Species")

# Create resampling
resampling <- rsmp("cv", folds = 5)
resampling$instantiate(task)

# Inspect
train_idx <- resampling$train_set(1)
test_idx <- resampling$test_set(1)
borg(task, train_idx, test_idx)
```

## Temporal Data

For time series or panel data:

```{r temporal-example}
# Create example time series data
set.seed(123)
n <- 500
ts_data <- data.frame(
  date = seq(as.Date("2020-01-01"), by = "day", length.out = n),
  value = cumsum(rnorm(n)),
  feature = rnorm(n)
)

train_idx <- 1:252
test_idx <- 253:365

# Validate with temporal ordering check
borg(ts_data, train_idx, test_idx, temporal_col = "date")
```

Rolling origin validation with rsample:

```{r, eval = has_rsample}
rolling <- rolling_origin(
  data = ts_data,
  initial = 365,
  assess = 30,
  cumulative = FALSE
)
borg(rolling, train_idx = NULL, test_idx = NULL)
```

## Spatial Data

For spatial cross-validation:

```{r spatial-example}
# Create example spatial data
set.seed(456)
n <- 100
spatial_data <- data.frame(
  longitude = runif(n, -10, 10),
  latitude = runif(n, -10, 10),
  response = rnorm(n),
  predictor = rnorm(n)
)

# Split by spatial blocks (west vs east)
train_idx <- which(spatial_data$longitude < 0)
test_idx <- which(spatial_data$longitude >= 0)

# Validate with spatial columns
borg(spatial_data, train_idx, test_idx, spatial_cols = c("longitude", "latitude"))
```

## Complete Workflow Validation

Validate an entire pipeline:

```{r workflow-validation}
# Example workflow with iris data
data <- iris
set.seed(789)
n <- nrow(data)
train_idx <- sample(n, 0.7 * n)
test_idx <- setdiff(1:n, train_idx)

# Pass a workflow list to borg()
result <- borg(list(
  data = data,
  train_idx = train_idx,
  test_idx = test_idx,
  target_col = "Species"
))

if (!result@is_valid) {
  print(result)
  message("Evaluation invalid - see risk report above")
}
```

## Automatic Rewriting

Attempt to fix leaky pipelines:

```{r rewrite-example}
# Create a workflow with a fixable issue
workflow <- list(
  data = iris,
  train_idx = 1:100,
  test_idx = 51:150  # Overlaps with train!
)

# Attempt automatic fixes
fixed <- borg_rewrite(workflow)

if (length(fixed$unfixable) > 0) {
  message("Could not fix: ", paste(fixed$unfixable, collapse = ", "))
}
```

Note: Some violations cannot be automatically fixed (e.g., index overlap
requires a new split).
